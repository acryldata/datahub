"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[77975],{15680:(e,n,a)=>{a.d(n,{xA:()=>p,yg:()=>g});var t=a(96540);function r(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function i(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,t)}return a}function o(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?i(Object(a),!0).forEach((function(n){r(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function s(e,n){if(null==e)return{};var a,t,r=function(e,n){if(null==e)return{};var a,t,r={},i=Object.keys(e);for(t=0;t<i.length;t++)a=i[t],n.indexOf(a)>=0||(r[a]=e[a]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(t=0;t<i.length;t++)a=i[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=t.createContext({}),d=function(e){var n=t.useContext(l),a=n;return e&&(a="function"==typeof e?e(n):o(o({},n),e)),a},p=function(e){var n=d(e.components);return t.createElement(l.Provider,{value:n},e.children)},m="mdxType",u={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},c=t.forwardRef((function(e,n){var a=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),m=d(a),c=r,g=m["".concat(l,".").concat(c)]||m[c]||u[c]||i;return a?t.createElement(g,o(o({ref:n},p),{},{components:a})):t.createElement(g,o({ref:n},p))}));function g(e,n){var a=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var i=a.length,o=new Array(i);o[0]=c;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s[m]="string"==typeof e?e:r,o[1]=s;for(var d=2;d<i;d++)o[d]=a[d];return t.createElement.apply(null,o)}return t.createElement.apply(null,a)}c.displayName="MDXCreateElement"},80997:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>p,contentTitle:()=>l,default:()=>g,frontMatter:()=>s,metadata:()=>d,toc:()=>m});a(96540);var t=a(15680);function r(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function i(e,n){return n=null!=n?n:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):function(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,t)}return a}(Object(n)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(n,a))})),e}function o(e,n){if(null==e)return{};var a,t,r=function(e,n){if(null==e)return{};var a,t,r={},i=Object.keys(e);for(t=0;t<i.length;t++)a=i[t],n.indexOf(a)>=0||(r[a]=e[a]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(t=0;t<i.length;t++)a=i[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}const s={sidebar_position:17,title:"ML Model",slug:"/generated/metamodel/entities/mlmodel-datahub",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/generated/metamodel/entities/mlModel-datahub.md"},l="ML Model",d={unversionedId:"docs/generated/metamodel/entities/mlModel-datahub",id:"docs/generated/metamodel/entities/mlModel-datahub",title:"ML Model",description:"The ML Model entity represents trained machine learning models across various ML platforms and frameworks. ML Models can be trained using different algorithms and frameworks (TensorFlow, PyTorch, Scikit-learn, etc.) and deployed to various platforms (MLflow, SageMaker, Vertex AI, etc.).",source:"@site/genDocs/docs/generated/metamodel/entities/mlModel-datahub.md",sourceDirName:"docs/generated/metamodel/entities",slug:"/generated/metamodel/entities/mlmodel-datahub",permalink:"/docs/generated/metamodel/entities/mlmodel-datahub",draft:!1,editUrl:"https://github.com/datahub-project/datahub/blob/master/docs/generated/metamodel/entities/mlModel-datahub.md",tags:[],version:"current",sidebarPosition:17,frontMatter:{sidebar_position:17,title:"ML Model",slug:"/generated/metamodel/entities/mlmodel-datahub",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/generated/metamodel/entities/mlModel-datahub.md"},sidebar:"overviewSidebar",previous:{title:"Assertion",permalink:"/docs/generated/metamodel/entities/assertion"},next:{title:"ML Model",permalink:"/docs/generated/metamodel/entities/mlmodel"}},p={},m=[{value:"Identity",id:"identity",level:2},{value:"Important Capabilities",id:"important-capabilities",level:2},{value:"Basic Model Information",id:"basic-model-information",level:3},{value:"Hyperparameters and Metrics",id:"hyperparameters-and-metrics",level:3},{value:"Intended Use and Ethical Considerations",id:"intended-use-and-ethical-considerations",level:3},{value:"Training and Evaluation Data",id:"training-and-evaluation-data",level:3},{value:"Direct Dataset References",id:"direct-dataset-references",level:4},{value:"Lineage via Training Runs",id:"lineage-via-training-runs",level:4},{value:"Factor Prompts and Quantitative Analysis",id:"factor-prompts-and-quantitative-analysis",level:3},{value:"Source Code and Cost",id:"source-code-and-cost",level:3},{value:"Training Runs and Experiments",id:"training-runs-and-experiments",level:3},{value:"Training Runs",id:"training-runs",level:4},{value:"Experiments",id:"experiments",level:4},{value:"Relationships and Lineage",id:"relationships-and-lineage",level:3},{value:"Core Relationships",id:"core-relationships",level:4},{value:"Lineage Graph Structure",id:"lineage-graph-structure",level:4},{value:"Tags, Terms, and Ownership",id:"tags-terms-and-ownership",level:3},{value:"Complete ML Workflow Example",id:"complete-ml-workflow-example",level:3},{value:"Code Examples",id:"code-examples",level:2},{value:"Querying ML Model Information",id:"querying-ml-model-information",level:3},{value:"Integration Points",id:"integration-points",level:2},{value:"Related Entities",id:"related-entities",level:3},{value:"GraphQL Resolvers",id:"graphql-resolvers",level:3},{value:"Ingestion Sources",id:"ingestion-sources",level:3},{value:"Notable Exceptions",id:"notable-exceptions",level:2},{value:"Model Versioning",id:"model-versioning",level:3},{value:"Version Properties Aspect",id:"version-properties-aspect",level:4},{value:"Version Aliases for A/B Testing",id:"version-aliases-for-ab-testing",level:4},{value:"Model Groups and Versioning",id:"model-groups-and-versioning",level:4},{value:"Platform-Specific Naming",id:"platform-specific-naming",level:3},{value:"Model Cards",id:"model-cards",level:3},{value:"Technical Reference",id:"technical-reference",level:2}],u={toc:m},c="wrapper";function g(e){var{components:n}=e,a=o(e,["components"]);return(0,t.yg)(c,i(function(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{},t=Object.keys(a);"function"==typeof Object.getOwnPropertySymbols&&(t=t.concat(Object.getOwnPropertySymbols(a).filter((function(e){return Object.getOwnPropertyDescriptor(a,e).enumerable})))),t.forEach((function(n){r(e,n,a[n])}))}return e}({},u,a),{components:n,mdxType:"MDXLayout"}),(0,t.yg)("h1",{id:"ml-model"},"ML Model"),(0,t.yg)("p",null,"The ML Model entity represents trained machine learning models across various ML platforms and frameworks. ML Models can be trained using different algorithms and frameworks (TensorFlow, PyTorch, Scikit-learn, etc.) and deployed to various platforms (MLflow, SageMaker, Vertex AI, etc.)."),(0,t.yg)("h2",{id:"identity"},"Identity"),(0,t.yg)("p",null,"ML Models are identified by three pieces of information:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},"The platform where the model is registered or deployed: this is the specific ML platform that hosts or manages this model. Examples are ",(0,t.yg)("inlineCode",{parentName:"li"},"mlflow"),", ",(0,t.yg)("inlineCode",{parentName:"li"},"sagemaker"),", ",(0,t.yg)("inlineCode",{parentName:"li"},"vertexai"),", ",(0,t.yg)("inlineCode",{parentName:"li"},"databricks"),", etc. See ",(0,t.yg)("a",{parentName:"li",href:"/docs/generated/metamodel/entities/dataplatform"},"dataplatform")," for more details."),(0,t.yg)("li",{parentName:"ul"},"The name of the model: this is the unique identifier for the model within the platform. The naming convention varies by platform:",(0,t.yg)("ul",{parentName:"li"},(0,t.yg)("li",{parentName:"ul"},"MLflow: typically uses the registered model name (e.g., ",(0,t.yg)("inlineCode",{parentName:"li"},"recommendation-model"),")"),(0,t.yg)("li",{parentName:"ul"},"SageMaker: uses the model name or model package group name (e.g., ",(0,t.yg)("inlineCode",{parentName:"li"},"product-recommendation-v1"),")"),(0,t.yg)("li",{parentName:"ul"},"Vertex AI: uses the model resource name (e.g., ",(0,t.yg)("inlineCode",{parentName:"li"},"projects/123/locations/us-central1/models/456"),")"))),(0,t.yg)("li",{parentName:"ul"},"The environment or origin where the model was trained: this is similar to the fabric concept for datasets, allowing you to distinguish between models in different environments (PROD, DEV, QA, etc.). The full list of supported environments is available in ",(0,t.yg)("a",{parentName:"li",href:"https://raw.githubusercontent.com/datahub-project/datahub/master/li-utils/src/main/pegasus/com/linkedin/common/FabricType.pdl"},"FabricType.pdl"),".")),(0,t.yg)("p",null,"An example of an ML Model identifier is ",(0,t.yg)("inlineCode",{parentName:"p"},"urn:li:mlModel:(urn:li:dataPlatform:mlflow,my-recommendation-model,PROD)"),"."),(0,t.yg)("h2",{id:"important-capabilities"},"Important Capabilities"),(0,t.yg)("h3",{id:"basic-model-information"},"Basic Model Information"),(0,t.yg)("p",null,"The core information about an ML Model is captured in the ",(0,t.yg)("inlineCode",{parentName:"p"},"mlModelProperties")," aspect. This includes:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Name and Description"),": Human-readable name and description of what the model does"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Model Type"),': The algorithm or architecture used (e.g., "Convolutional Neural Network", "Random Forest", "BERT")'),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Version"),": Version information using the ",(0,t.yg)("inlineCode",{parentName:"li"},"versionProperties")," aspect"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Timestamps"),": Created and last modified timestamps"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Custom Properties"),": Flexible key-value pairs for platform-specific metadata (e.g., framework version, model format)")),(0,t.yg)("p",null,"The following code snippet shows you how to create a basic ML Model:"),(0,t.yg)("details",null,(0,t.yg)("summary",null,"Python SDK: Create an ML Model"),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre",className:"language-python"},'from datahub.metadata.urns import MlModelGroupUrn\nfrom datahub.sdk import DataHubClient\nfrom datahub.sdk.mlmodel import MLModel\n\nclient = DataHubClient.from_env()\n\nmlmodel = MLModel(\n    id="customer-churn-predictor",\n    name="Customer Churn Prediction Model",\n    platform="mlflow",\n    description="A gradient boosting model that predicts customer churn based on usage patterns and engagement metrics",\n    custom_properties={\n        "framework": "xgboost",\n        "framework_version": "1.7.0",\n        "model_format": "pickle",\n    },\n    model_group=MlModelGroupUrn(platform="mlflow", name="customer-churn-models"),\n)\n\nclient.entities.upsert(mlmodel)\n\n'))),(0,t.yg)("h3",{id:"hyperparameters-and-metrics"},"Hyperparameters and Metrics"),(0,t.yg)("p",null,"ML Models can capture both the hyperparameters used during training and various metrics from training and production:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Hyperparameters"),": Configuration values that control the training process (learning rate, batch size, number of epochs, etc.)"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Training Metrics"),": Performance metrics from the training process (accuracy, loss, F1 score, etc.)"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Online Metrics"),": Performance metrics from production deployment (latency, throughput, drift, etc.)")),(0,t.yg)("p",null,"These are stored in the ",(0,t.yg)("inlineCode",{parentName:"p"},"mlModelProperties")," aspect as structured lists of parameters and metrics."),(0,t.yg)("details",null,(0,t.yg)("summary",null,"Python SDK: Add hyperparameters and metrics to an ML Model"),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre",className:"language-python"},'from datahub.metadata.urns import CorpUserUrn, DomainUrn, MlModelUrn, TagUrn\nfrom datahub.sdk import DataHubClient\n\nclient = DataHubClient.from_env()\n\nmlmodel = client.entities.get(\n    MlModelUrn(platform="mlflow", name="customer-churn-predictor")\n)\n\nmlmodel.set_hyper_params(\n    {\n        "learning_rate": "0.1",\n        "max_depth": "6",\n        "n_estimators": "100",\n        "subsample": "0.8",\n        "colsample_bytree": "0.8",\n    }\n)\n\nmlmodel.set_training_metrics(\n    {\n        "accuracy": "0.87",\n        "precision": "0.84",\n        "recall": "0.82",\n        "f1_score": "0.83",\n        "auc_roc": "0.91",\n    }\n)\n\nmlmodel.add_owner(CorpUserUrn("data_science_team"))\n\nmlmodel.add_tag(TagUrn("production"))\nmlmodel.add_tag(TagUrn("classification"))\n\nmlmodel.set_domain(DomainUrn("urn:li:domain:customer-analytics"))\n\nclient.entities.update(mlmodel)\n\n'))),(0,t.yg)("h3",{id:"intended-use-and-ethical-considerations"},"Intended Use and Ethical Considerations"),(0,t.yg)("p",null,"DataHub supports comprehensive model documentation following ML model card best practices. These aspects help stakeholders understand the appropriate use cases and ethical implications of using the model:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Intended Use")," (",(0,t.yg)("inlineCode",{parentName:"li"},"intendedUse")," aspect): Documents primary use cases, intended users, and out-of-scope applications"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Ethical Considerations")," (",(0,t.yg)("inlineCode",{parentName:"li"},"mlModelEthicalConsiderations")," aspect): Documents use of sensitive data, risks and harms, mitigation strategies"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Caveats and Recommendations")," (",(0,t.yg)("inlineCode",{parentName:"li"},"mlModelCaveatsAndRecommendations")," aspect): Additional considerations, ideal dataset characteristics, and usage recommendations")),(0,t.yg)("p",null,"These aspects align with responsible AI practices and help ensure models are used appropriately."),(0,t.yg)("h3",{id:"training-and-evaluation-data"},"Training and Evaluation Data"),(0,t.yg)("p",null,"ML Models can document their training and evaluation datasets in two complementary ways:"),(0,t.yg)("h4",{id:"direct-dataset-references"},"Direct Dataset References"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Training Data")," (",(0,t.yg)("inlineCode",{parentName:"li"},"mlModelTrainingData")," aspect): Datasets used to train the model, including preprocessing information and motivation for dataset selection"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Evaluation Data")," (",(0,t.yg)("inlineCode",{parentName:"li"},"mlModelEvaluationData")," aspect): Datasets used for model evaluation and testing")),(0,t.yg)("p",null,"Each dataset reference includes the dataset URN, motivation for using that dataset, and any preprocessing steps applied. This creates direct lineage relationships between models and their training data."),(0,t.yg)("h4",{id:"lineage-via-training-runs"},"Lineage via Training Runs"),(0,t.yg)("p",null,"Training runs (",(0,t.yg)("inlineCode",{parentName:"p"},"dataProcessInstance")," entities) provide an alternative and often more detailed way to capture training lineage:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},"Training runs declare their input datasets via ",(0,t.yg)("inlineCode",{parentName:"li"},"dataProcessInstanceInput")," aspect"),(0,t.yg)("li",{parentName:"ul"},"Training runs declare their output datasets via ",(0,t.yg)("inlineCode",{parentName:"li"},"dataProcessInstanceOutput")," aspect"),(0,t.yg)("li",{parentName:"ul"},"Models reference training runs via the ",(0,t.yg)("inlineCode",{parentName:"li"},"trainingJobs")," field")),(0,t.yg)("p",null,"This creates indirect lineage: ",(0,t.yg)("inlineCode",{parentName:"p"},"Dataset \u2192 Training Run \u2192 Model")),(0,t.yg)("p",null,(0,t.yg)("strong",{parentName:"p"},"When to use each approach:")),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},"Use ",(0,t.yg)("strong",{parentName:"li"},"direct dataset references")," for simple documentation of what data was used"),(0,t.yg)("li",{parentName:"ul"},"Use ",(0,t.yg)("strong",{parentName:"li"},"training runs")," for complete lineage tracking including:",(0,t.yg)("ul",{parentName:"li"},(0,t.yg)("li",{parentName:"ul"},"Multiple training/validation/test datasets"),(0,t.yg)("li",{parentName:"ul"},"Metrics and hyperparameters from the training process"),(0,t.yg)("li",{parentName:"ul"},"Temporal tracking (when the training occurred)"),(0,t.yg)("li",{parentName:"ul"},"Connection to experiments for comparing multiple training attempts")))),(0,t.yg)("p",null,"Most production ML systems should use training runs for comprehensive lineage tracking."),(0,t.yg)("h3",{id:"factor-prompts-and-quantitative-analysis"},"Factor Prompts and Quantitative Analysis"),(0,t.yg)("p",null,"For detailed model analysis and performance reporting:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Factor Prompts")," (",(0,t.yg)("inlineCode",{parentName:"li"},"mlModelFactorPrompts")," aspect): Factors that may affect model performance (demographic groups, environmental conditions, etc.)"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Quantitative Analyses")," (",(0,t.yg)("inlineCode",{parentName:"li"},"mlModelQuantitativeAnalyses")," aspect): Links to dashboards or reports showing disaggregated performance metrics across different factors"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Metrics")," (",(0,t.yg)("inlineCode",{parentName:"li"},"mlModelMetrics")," aspect): Detailed metrics with descriptions beyond simple training/online metrics")),(0,t.yg)("h3",{id:"source-code-and-cost"},"Source Code and Cost"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Source Code")," (",(0,t.yg)("inlineCode",{parentName:"li"},"sourceCode")," aspect): Links to model training code, notebooks, or repositories (GitHub, GitLab, etc.)"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Cost")," (",(0,t.yg)("inlineCode",{parentName:"li"},"cost")," aspect): Cost attribution information for tracking model training and inference expenses")),(0,t.yg)("h3",{id:"training-runs-and-experiments"},"Training Runs and Experiments"),(0,t.yg)("p",null,"ML Models in DataHub can be linked to their training runs and experiments, providing complete lineage from raw data through training to deployed models."),(0,t.yg)("h4",{id:"training-runs"},"Training Runs"),(0,t.yg)("p",null,"Training runs represent specific executions of model training jobs. In DataHub, training runs are modeled as ",(0,t.yg)("inlineCode",{parentName:"p"},"dataProcessInstance")," entities with a specialized subtype:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Entity Type"),": ",(0,t.yg)("inlineCode",{parentName:"li"},"dataProcessInstance")),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Subtype"),": ",(0,t.yg)("inlineCode",{parentName:"li"},"MLAssetSubTypes.MLFLOW_TRAINING_RUN")),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Key Aspects"),":",(0,t.yg)("ul",{parentName:"li"},(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("inlineCode",{parentName:"li"},"dataProcessInstanceProperties"),": Basic properties like name, timestamps, and custom properties"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("inlineCode",{parentName:"li"},"mlTrainingRunProperties"),": ML-specific properties including:",(0,t.yg)("ul",{parentName:"li"},(0,t.yg)("li",{parentName:"ul"},"Training metrics (accuracy, loss, F1 score, etc.)"),(0,t.yg)("li",{parentName:"ul"},"Hyperparameters (learning rate, batch size, epochs, etc.)"),(0,t.yg)("li",{parentName:"ul"},"Output URLs (model artifacts, checkpoints)"),(0,t.yg)("li",{parentName:"ul"},"External URLs (links to training dashboards)"))),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("inlineCode",{parentName:"li"},"dataProcessInstanceInput"),": Input datasets used for training"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("inlineCode",{parentName:"li"},"dataProcessInstanceOutput"),": Output datasets (predictions, feature importance, etc.)"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("inlineCode",{parentName:"li"},"dataProcessInstanceRunEvent"),": Start, completion, and failure events")))),(0,t.yg)("p",null,"Training runs create lineage relationships showing:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Upstream"),": Which datasets were used for training"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Downstream"),": Which models were produced by the training run")),(0,t.yg)("p",null,"Models reference their training runs through the ",(0,t.yg)("inlineCode",{parentName:"p"},"trainingJobs")," field in ",(0,t.yg)("inlineCode",{parentName:"p"},"mlModelProperties"),", and model groups can also reference training runs to track all training activity for a model family."),(0,t.yg)("h4",{id:"experiments"},"Experiments"),(0,t.yg)("p",null,"Experiments organize related training runs into logical groups, typically representing a series of attempts to optimize a model or compare different approaches. In DataHub, experiments are modeled as ",(0,t.yg)("inlineCode",{parentName:"p"},"container")," entities:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Entity Type"),": ",(0,t.yg)("inlineCode",{parentName:"li"},"container")),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Subtype"),": ",(0,t.yg)("inlineCode",{parentName:"li"},"MLAssetSubTypes.MLFLOW_EXPERIMENT")),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Purpose"),": Group related training runs for organization and comparison")),(0,t.yg)("p",null,"Training runs belong to experiments through the ",(0,t.yg)("inlineCode",{parentName:"p"},"container")," aspect, creating a hierarchy:"),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre"},'Experiment: "Customer Churn Prediction"\n\u251c\u2500\u2500 Training Run 1: baseline model\n\u251c\u2500\u2500 Training Run 2: with feature engineering\n\u251c\u2500\u2500 Training Run 3: hyperparameter tuning\n\u2514\u2500\u2500 Training Run 4: final production model\n')),(0,t.yg)("p",null,"This structure mirrors common ML platform patterns (like MLflow's experiment/run hierarchy) and enables:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},"Comparing metrics across multiple training attempts"),(0,t.yg)("li",{parentName:"ul"},"Tracking the evolution of a model through iterations"),(0,t.yg)("li",{parentName:"ul"},"Understanding which approaches were tried and their results"),(0,t.yg)("li",{parentName:"ul"},"Organizing training work by project or objective")),(0,t.yg)("details",null,(0,t.yg)("summary",null,"Python SDK: Create training runs and experiments"),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre",className:"language-python"},'import argparse\nfrom datetime import datetime\n\nfrom dh_ai_client import DatahubAIClient\n\nfrom datahub.emitter.mcp_builder import (\n    ContainerKey,\n)\nfrom datahub.ingestion.source.common.subtypes import MLAssetSubTypes\nfrom datahub.metadata.com.linkedin.pegasus2avro.dataprocess import RunResultType\nfrom datahub.metadata.schema_classes import (\n    AuditStampClass,\n    DataProcessInstancePropertiesClass,\n    MLHyperParamClass,\n    MLMetricClass,\n    MLTrainingRunPropertiesClass,\n)\nfrom datahub.metadata.urns import (\n    CorpUserUrn,\n    DataProcessInstanceUrn,\n    GlossaryTermUrn,\n    TagUrn,\n)\nfrom datahub.sdk.container import Container\nfrom datahub.sdk.dataset import Dataset\nfrom datahub.sdk.mlmodel import MLModel\nfrom datahub.sdk.mlmodelgroup import MLModelGroup\n\nparser = argparse.ArgumentParser()\nparser.add_argument("--token", required=False, help="DataHub access token")\nparser.add_argument(\n    "--server_url",\n    required=False,\n    default="http://localhost:8080",\n    help="DataHub server URL (defaults to http://localhost:8080)",\n)\nargs = parser.parse_args()\n\n# Initialize client\nclient = DatahubAIClient(token=args.token, server_url=args.server_url)\n\n# Use a unique prefix for all IDs to avoid conflicts\nprefix = "test"\n\n# Define all entity IDs upfront\n# Basic entity IDs\nbasic_model_group_id = f"{prefix}_basic_group"\nbasic_model_id = f"{prefix}_basic_model"\nbasic_experiment_id = f"{prefix}_basic_experiment"\nbasic_run_id = f"{prefix}_basic_run"\nbasic_dataset_id = f"{prefix}_basic_dataset"\n\n# Advanced entity IDs\nadvanced_model_group_id = f"{prefix}_airline_forecast_models_group"\nadvanced_model_id = f"{prefix}_arima_model"\nadvanced_experiment_id = f"{prefix}_airline_forecast_experiment"\nadvanced_run_id = f"{prefix}_simple_training_run"\nadvanced_input_dataset_id = f"{prefix}_iris_input"\nadvanced_output_dataset_id = f"{prefix}_iris_output"\n\n# Display names with prefix\nbasic_model_group_name = f"{prefix} Basic Group"\nbasic_model_name = f"{prefix} Basic Model"\nbasic_experiment_name = f"{prefix} Basic Experiment"\nbasic_run_name = f"{prefix} Basic Run"\nbasic_dataset_name = f"{prefix} Basic Dataset"\n\nadvanced_model_group_name = f"{prefix} Airline Forecast Models Group"\nadvanced_model_name = f"{prefix} ARIMA Model"\nadvanced_experiment_name = f"{prefix} Airline Forecast Experiment"\nadvanced_run_name = f"{prefix} Simple Training Run"\nadvanced_input_dataset_name = f"{prefix} Iris Training Input Data"\nadvanced_output_dataset_name = f"{prefix} Iris Model Output Data"\n\n\ndef create_basic_model_group():\n    """Create a basic model group."""\n    print("Creating basic model group...")\n    basic_model_group = MLModelGroup(\n        id=basic_model_group_id,\n        platform="mlflow",\n        name=basic_model_group_name,\n    )\n    client._emit_mcps(basic_model_group.as_mcps())\n    return basic_model_group\n\n\ndef create_advanced_model_group():\n    """Create an advanced model group."""\n    print("Creating advanced model group...")\n    advanced_model_group = MLModelGroup(\n        id=advanced_model_group_id,\n        platform="mlflow",\n        name=advanced_model_group_name,\n        description="Group of models for airline passenger forecasting",\n        created=datetime.now(),\n        last_modified=datetime.now(),\n        owners=[CorpUserUrn("urn:li:corpuser:datahub")],\n        external_url="https://www.linkedin.com/in/datahub",\n        tags=["urn:li:tag:forecasting", "urn:li:tag:arima"],\n        terms=["urn:li:glossaryTerm:forecasting"],\n        custom_properties={"team": "forecasting"},\n    )\n    client._emit_mcps(advanced_model_group.as_mcps())\n    return advanced_model_group\n\n\ndef create_basic_model():\n    """Create a basic model."""\n    print("Creating basic model...")\n    basic_model = MLModel(\n        id=basic_model_id,\n        platform="mlflow",\n        name=basic_model_name,\n    )\n    client._emit_mcps(basic_model.as_mcps())\n    return basic_model\n\n\ndef create_advanced_model():\n    """Create an advanced model."""\n    print("Creating advanced model...")\n    advanced_model = MLModel(\n        id=advanced_model_id,\n        platform="mlflow",\n        name=advanced_model_name,\n        description="ARIMA model for airline passenger forecasting",\n        created=datetime.now(),\n        last_modified=datetime.now(),\n        owners=[CorpUserUrn("urn:li:corpuser:datahub")],\n        external_url="https://www.linkedin.com/in/datahub",\n        tags=["urn:li:tag:forecasting", "urn:li:tag:arima"],\n        terms=["urn:li:glossaryTerm:forecasting"],\n        custom_properties={"team": "forecasting"},\n        version="1",\n        aliases=["champion"],\n        hyper_params={"learning_rate": "0.01"},\n        training_metrics={"accuracy": "0.9"},\n    )\n    client._emit_mcps(advanced_model.as_mcps())\n    return advanced_model\n\n\ndef create_basic_experiment():\n    """Create a basic experiment."""\n    print("Creating basic experiment...")\n    basic_experiment = Container(\n        container_key=ContainerKey(platform="mlflow", name=basic_experiment_id),\n        display_name=basic_experiment_name,\n    )\n    client._emit_mcps(basic_experiment.as_mcps())\n    return basic_experiment\n\n\ndef create_advanced_experiment():\n    """Create an advanced experiment."""\n    print("Creating advanced experiment...")\n    advanced_experiment = Container(\n        container_key=ContainerKey(platform="mlflow", name=advanced_experiment_id),\n        display_name=advanced_experiment_name,\n        description="Experiment to forecast airline passenger numbers",\n        extra_properties={"team": "forecasting"},\n        created=datetime(2025, 4, 9, 22, 30),\n        last_modified=datetime(2025, 4, 9, 22, 30),\n        subtype=MLAssetSubTypes.MLFLOW_EXPERIMENT,\n    )\n    client._emit_mcps(advanced_experiment.as_mcps())\n    return advanced_experiment\n\n\ndef create_basic_training_run():\n    """Create a basic training run."""\n    print("Creating basic training run...")\n    basic_run_urn = client.create_training_run(\n        run_id=basic_run_id,\n        run_name=basic_run_name,\n    )\n    return basic_run_urn\n\n\ndef create_advanced_training_run():\n    """Create an advanced training run."""\n    print("Creating advanced training run...")\n    advanced_run_urn = client.create_training_run(\n        run_id=advanced_run_id,\n        properties=DataProcessInstancePropertiesClass(\n            name=advanced_run_name,\n            created=AuditStampClass(\n                time=1628580000000, actor="urn:li:corpuser:datahub"\n            ),\n            customProperties={"team": "forecasting"},\n        ),\n        training_run_properties=MLTrainingRunPropertiesClass(\n            id=advanced_run_id,\n            outputUrls=["s3://my-bucket/output"],\n            trainingMetrics=[MLMetricClass(name="accuracy", value="0.9")],\n            hyperParams=[MLHyperParamClass(name="learning_rate", value="0.01")],\n            externalUrl="https:localhost:5000",\n        ),\n        run_result=RunResultType.FAILURE,\n        start_timestamp=1628580000000,\n        end_timestamp=1628580001000,\n    )\n    return advanced_run_urn\n\n\ndef create_basic_dataset():\n    """Create a basic dataset."""\n    print("Creating basic dataset...")\n    basic_input_dataset = Dataset(\n        platform="snowflake",\n        name=basic_dataset_id,\n        display_name=basic_dataset_name,\n    )\n    client._emit_mcps(basic_input_dataset.as_mcps())\n    return basic_input_dataset\n\n\ndef create_advanced_datasets():\n    """Create advanced datasets."""\n    print("Creating advanced datasets...")\n    advanced_input_dataset = Dataset(\n        platform="snowflake",\n        name=advanced_input_dataset_id,\n        description="Raw Iris dataset used for training ML models",\n        schema=[("id", "number"), ("name", "string"), ("species", "string")],\n        display_name=advanced_input_dataset_name,\n        tags=["urn:li:tag:ml_data", "urn:li:tag:iris"],\n        terms=["urn:li:glossaryTerm:raw_data"],\n        owners=[CorpUserUrn("urn:li:corpuser:datahub")],\n        custom_properties={\n            "data_source": "UCI Repository",\n            "records": "150",\n            "features": "4",\n        },\n    )\n    client._emit_mcps(advanced_input_dataset.as_mcps())\n\n    advanced_output_dataset = Dataset(\n        platform="snowflake",\n        name=advanced_output_dataset_id,\n        description="Processed Iris dataset with model predictions",\n        schema=[("id", "number"), ("name", "string"), ("species", "string")],\n        display_name=advanced_output_dataset_name,\n        tags=["urn:li:tag:ml_data", "urn:li:tag:predictions"],\n        terms=["urn:li:glossaryTerm:model_output"],\n        owners=[CorpUserUrn("urn:li:corpuser:datahub")],\n        custom_properties={\n            "model_version": "1.0",\n            "records": "150",\n            "accuracy": "0.95",\n        },\n    )\n    client._emit_mcps(advanced_output_dataset.as_mcps())\n    return advanced_input_dataset, advanced_output_dataset\n\n\n# Split relationship functions into individual top-level functions\ndef add_model_to_model_group(model, model_group):\n    """Add model to model group relationship."""\n    print("Adding model to model group...")\n    model.set_model_group(model_group.urn)\n    client._emit_mcps(model.as_mcps())\n\n\ndef add_run_to_experiment(run_urn, experiment):\n    """Add run to experiment relationship."""\n    print("Adding run to experiment...")\n    client.add_run_to_experiment(run_urn=run_urn, experiment_urn=str(experiment.urn))\n\n\ndef add_run_to_model(model, run_id):\n    """Add run to model relationship."""\n    print("Adding run to model...")\n    model.add_training_job(DataProcessInstanceUrn(run_id))\n    client._emit_mcps(model.as_mcps())\n\n\ndef add_run_to_model_group(model_group, run_id):\n    """Add run to model group relationship."""\n    print("Adding run to model group...")\n    model_group.add_training_job(DataProcessInstanceUrn(run_id))\n    client._emit_mcps(model_group.as_mcps())\n\n\ndef add_input_dataset_to_run(run_urn, input_dataset):\n    """Add input dataset to run relationship."""\n    print("Adding input dataset to run...")\n    client.add_input_datasets_to_run(\n        run_urn=run_urn, dataset_urns=[str(input_dataset.urn)]\n    )\n\n\ndef add_output_dataset_to_run(run_urn, output_dataset):\n    """Add output dataset to run relationship."""\n    print("Adding output dataset to run...")\n    client.add_output_datasets_to_run(\n        run_urn=run_urn, dataset_urns=[str(output_dataset.urn)]\n    )\n\n\ndef update_model_properties(model):\n    """Update model properties."""\n    print("Updating model properties...")\n\n    # Update model version\n    model.set_version("2")\n\n    # Add tags and terms\n    model.add_tag(TagUrn("marketing"))\n    model.add_term(GlossaryTermUrn("marketing"))\n\n    # Add version alias\n    model.add_version_alias("challenger")\n\n    # Save the changes\n    client._emit_mcps(model.as_mcps())\n\n\ndef update_model_group_properties(model_group):\n    """Update model group properties."""\n    print("Updating model group properties...")\n\n    # Update description\n    model_group.set_description("Updated description for airline forecast models")\n\n    # Add tags and terms\n    model_group.add_tag(TagUrn("production"))\n    model_group.add_term(GlossaryTermUrn("time-series"))\n\n    # Update custom properties\n    model_group.set_custom_properties(\n        {"team": "forecasting", "business_unit": "operations", "status": "active"}\n    )\n\n    # Save the changes\n    client._emit_mcps(model_group.as_mcps())\n\n\ndef update_experiment_properties():\n    """Update experiment properties."""\n    print("Updating experiment properties...")\n\n    # Create a container object for the existing experiment\n    existing_experiment = Container(\n        container_key=ContainerKey(platform="mlflow", name=advanced_experiment_id),\n        display_name=advanced_experiment_name,\n    )\n\n    # Update properties\n    existing_experiment.set_description(\n        "Updated experiment for forecasting passenger numbers"\n    )\n    existing_experiment.add_tag(TagUrn("time-series"))\n    existing_experiment.add_term(GlossaryTermUrn("forecasting"))\n    existing_experiment.set_custom_properties(\n        {"team": "forecasting", "priority": "high", "status": "active"}\n    )\n\n    # Save the changes\n    client._emit_mcps(existing_experiment.as_mcps())\n\n\ndef main():\n    # Parse arguments\n    print("Creating AI assets...")\n\n    # Comment in/out the functions you want to run\n    # Create basic entities\n    create_basic_model_group()\n    create_basic_model()\n    create_basic_experiment()\n    create_basic_training_run()\n    create_basic_dataset()\n\n    # Create advanced entities\n    advanced_model_group = create_advanced_model_group()\n    advanced_model = create_advanced_model()\n    advanced_experiment = create_advanced_experiment()\n    advanced_run_urn = create_advanced_training_run()\n    advanced_input_dataset, advanced_output_dataset = create_advanced_datasets()\n\n    # # Create relationships - each can be commented out independently\n    add_model_to_model_group(advanced_model, advanced_model_group)\n    add_run_to_experiment(advanced_run_urn, advanced_experiment)\n    add_run_to_model(advanced_model, advanced_run_id)\n    add_run_to_model_group(advanced_model_group, advanced_run_id)\n    add_input_dataset_to_run(advanced_run_urn, advanced_input_dataset)\n    add_output_dataset_to_run(advanced_run_urn, advanced_output_dataset)\n\n    # # Update properties - each can be commented out independently\n    update_model_properties(advanced_model)\n    update_model_group_properties(advanced_model_group)\n    update_experiment_properties()\n\n    print("All done! AI entities created successfully.")\n\n\nif __name__ == "__main__":\n    main()\n\n'))),(0,t.yg)("h3",{id:"relationships-and-lineage"},"Relationships and Lineage"),(0,t.yg)("p",null,"ML Models support rich relationship modeling through various aspects and fields:"),(0,t.yg)("h4",{id:"core-relationships"},"Core Relationships"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("p",{parentName:"li"},(0,t.yg)("strong",{parentName:"p"},"Model Groups")," (via ",(0,t.yg)("inlineCode",{parentName:"p"},"groups")," field in ",(0,t.yg)("inlineCode",{parentName:"p"},"mlModelProperties"),"): Models can belong to ",(0,t.yg)("inlineCode",{parentName:"p"},"mlModelGroup")," entities, creating a ",(0,t.yg)("inlineCode",{parentName:"p"},"MemberOf")," relationship. This organizes related models into logical families or collections.")),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("p",{parentName:"li"},(0,t.yg)("strong",{parentName:"p"},"Training Runs")," (via ",(0,t.yg)("inlineCode",{parentName:"p"},"trainingJobs")," field in ",(0,t.yg)("inlineCode",{parentName:"p"},"mlModelProperties"),"): Models reference ",(0,t.yg)("inlineCode",{parentName:"p"},"dataProcessInstance")," entities with ",(0,t.yg)("inlineCode",{parentName:"p"},"MLFLOW_TRAINING_RUN")," subtype that produced them. This creates upstream lineage showing:"),(0,t.yg)("ul",{parentName:"li"},(0,t.yg)("li",{parentName:"ul"},"Which training run created this model"),(0,t.yg)("li",{parentName:"ul"},"What datasets were used for training (via the training run's input datasets)"),(0,t.yg)("li",{parentName:"ul"},"What hyperparameters and metrics were recorded"),(0,t.yg)("li",{parentName:"ul"},"Which experiment the training run belonged to"))),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("p",{parentName:"li"},(0,t.yg)("strong",{parentName:"p"},"Features")," (via ",(0,t.yg)("inlineCode",{parentName:"p"},"mlFeatures")," field in ",(0,t.yg)("inlineCode",{parentName:"p"},"mlModelProperties"),"): Models can consume ",(0,t.yg)("inlineCode",{parentName:"p"},"mlFeature")," entities, creating a ",(0,t.yg)("inlineCode",{parentName:"p"},"Consumes")," relationship. This documents:"),(0,t.yg)("ul",{parentName:"li"},(0,t.yg)("li",{parentName:"ul"},"Which features are required for model inference"),(0,t.yg)("li",{parentName:"ul"},"The complete feature set used during training"),(0,t.yg)("li",{parentName:"ul"},"Dependencies on feature stores or feature tables"))),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("p",{parentName:"li"},(0,t.yg)("strong",{parentName:"p"},"Deployments")," (via ",(0,t.yg)("inlineCode",{parentName:"p"},"deployments")," field in ",(0,t.yg)("inlineCode",{parentName:"p"},"mlModelProperties"),"): Models can be deployed to ",(0,t.yg)("inlineCode",{parentName:"p"},"mlModelDeployment")," entities, representing running model endpoints in various environments (production, staging, etc.)")),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("p",{parentName:"li"},(0,t.yg)("strong",{parentName:"p"},"Training Datasets")," (via ",(0,t.yg)("inlineCode",{parentName:"p"},"mlModelTrainingData")," aspect): Direct references to datasets used for training, including preprocessing information and motivation for dataset selection")),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("p",{parentName:"li"},(0,t.yg)("strong",{parentName:"p"},"Evaluation Datasets")," (via ",(0,t.yg)("inlineCode",{parentName:"p"},"mlModelEvaluationData")," aspect): References to datasets used for model evaluation and testing"))),(0,t.yg)("h4",{id:"lineage-graph-structure"},"Lineage Graph Structure"),(0,t.yg)("p",null,"These relationships create a comprehensive lineage graph:"),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre"},"Training Datasets \u2192 Training Run \u2192 ML Model \u2192 ML Model Deployment\n                         \u2193\n                    Experiment\n\nFeature Tables \u2192 ML Features \u2192 ML Model\n\nML Model Group \u2190 ML Model\n")),(0,t.yg)("p",null,"This enables powerful queries such as:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},'"Show me all datasets that influenced this model\'s predictions"'),(0,t.yg)("li",{parentName:"ul"},'"Which models will be affected if this dataset schema changes?"'),(0,t.yg)("li",{parentName:"ul"},'"What\'s the full history of training runs that created versions of this model?"'),(0,t.yg)("li",{parentName:"ul"},'"Which production endpoints are serving this model?"')),(0,t.yg)("details",null,(0,t.yg)("summary",null,"Python SDK: Update model-specific aspects"),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre",className:"language-python"},'import datahub.metadata.schema_classes as models\nfrom datahub.metadata.urns import DatasetUrn, MlModelUrn\nfrom datahub.sdk import DataHubClient\n\nclient = DataHubClient.from_env()\n\nmodel_urn = MlModelUrn(platform="mlflow", name="customer-churn-predictor")\n\nmlmodel = client.entities.get(model_urn)\n\nintended_use = models.IntendedUseClass(\n    primaryUses=[\n        "Predict customer churn to enable proactive retention campaigns",\n        "Identify high-risk customers for targeted interventions",\n    ],\n    primaryUsers=[models.IntendedUserTypeClass.ENTERPRISE],\n    outOfScopeUses=[\n        "Not suitable for real-time predictions (batch inference only)",\n        "Not trained on international markets outside North America",\n    ],\n)\n\nmlmodel._set_aspect(intended_use)\n\ntraining_data = models.TrainingDataClass(\n    trainingData=[\n        models.BaseDataClass(\n            dataset=str(\n                DatasetUrn(\n                    platform="snowflake", name="prod.analytics.customer_features"\n                )\n            ),\n            motivation="Historical customer data with confirmed churn labels",\n            preProcessing=[\n                "Removed customers with less than 30 days of history",\n                "Standardized numerical features using StandardScaler",\n                "One-hot encoded categorical variables",\n            ],\n        )\n    ]\n)\n\nmlmodel._set_aspect(training_data)\n\nsource_code = models.SourceCodeClass(\n    sourceCode=[\n        models.SourceCodeUrlClass(\n            type=models.SourceCodeUrlTypeClass.ML_MODEL_SOURCE_CODE,\n            sourceCodeUrl="https://github.com/example/ml-models/tree/main/churn-predictor",\n        )\n    ]\n)\n\nmlmodel._set_aspect(source_code)\n\nethical_considerations = models.EthicalConsiderationsClass(\n    data=["Model uses demographic data (age, location) which may be sensitive"],\n    risksAndHarms=[\n        "Predictions may disproportionately affect certain customer segments",\n        "False positives could lead to unnecessary retention spending",\n    ],\n    mitigations=[\n        "Regular bias audits conducted quarterly",\n        "Human review required for high-value customer interventions",\n    ],\n)\n\nmlmodel._set_aspect(ethical_considerations)\n\nclient.entities.update(mlmodel)\n\nprint(f"Updated aspects for model: {model_urn}")\n\n'))),(0,t.yg)("h3",{id:"tags-terms-and-ownership"},"Tags, Terms, and Ownership"),(0,t.yg)("p",null,"Like other DataHub entities, ML Models support:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Tags")," (",(0,t.yg)("inlineCode",{parentName:"li"},"globalTags"),' aspect): Flexible categorization (e.g., "pii-model", "production-ready", "experimental")'),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Glossary Terms")," (",(0,t.yg)("inlineCode",{parentName:"li"},"glossaryTerms"),' aspect): Business concepts (e.g., "Customer Churn", "Fraud Detection")'),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Ownership")," (",(0,t.yg)("inlineCode",{parentName:"li"},"ownership")," aspect): Individuals or teams responsible for the model (data scientists, ML engineers, etc.)"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Domains")," (",(0,t.yg)("inlineCode",{parentName:"li"},"domains"),' aspect): Organizational grouping (e.g., "Recommendations", "Risk Management")')),(0,t.yg)("h3",{id:"complete-ml-workflow-example"},"Complete ML Workflow Example"),(0,t.yg)("p",null,"The following example demonstrates a complete ML model lifecycle in DataHub, showing how all the pieces work together:"),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre"},"1. Create Model Group\n   \u2193\n2. Create Experiment (Container)\n   \u2193\n3. Create Training Run (DataProcessInstance)\n   \u251c\u2500\u2500 Link input datasets\n   \u251c\u2500\u2500 Link output datasets\n   \u2514\u2500\u2500 Add metrics and hyperparameters\n   \u2193\n4. Create Model\n   \u251c\u2500\u2500 Set version and aliases\n   \u251c\u2500\u2500 Link to model group\n   \u251c\u2500\u2500 Link to training run\n   \u251c\u2500\u2500 Add hyperparameters and metrics\n   \u2514\u2500\u2500 Add ownership and tags\n   \u2193\n5. Link Training Run to Experiment\n   \u2193\n6. Update Model properties as needed\n   \u251c\u2500\u2500 Change version aliases (champion \u2192 challenger)\n   \u251c\u2500\u2500 Add additional tags/terms\n   \u2514\u2500\u2500 Update metrics from production\n")),(0,t.yg)("p",null,"This workflow creates rich lineage showing:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},"Which datasets trained the model"),(0,t.yg)("li",{parentName:"ul"},"What experiments and training runs were involved"),(0,t.yg)("li",{parentName:"ul"},"How the model evolved through versions"),(0,t.yg)("li",{parentName:"ul"},"Which version is deployed (via aliases)"),(0,t.yg)("li",{parentName:"ul"},"Who owns and maintains the model")),(0,t.yg)("details",null,(0,t.yg)("summary",null,"Complete Python Example: Full ML Workflow"),(0,t.yg)("p",null,"See the comprehensive example in ",(0,t.yg)("inlineCode",{parentName:"p"},"/metadata-ingestion/examples/ai/dh_ai_docs_demo.py")," which demonstrates:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},"Creating model groups with metadata"),(0,t.yg)("li",{parentName:"ul"},"Creating experiments to organize training runs"),(0,t.yg)("li",{parentName:"ul"},"Creating training runs with metrics, hyperparameters, and dataset lineage"),(0,t.yg)("li",{parentName:"ul"},"Creating models with versions and aliases"),(0,t.yg)("li",{parentName:"ul"},"Linking all entities together to form complete lineage"),(0,t.yg)("li",{parentName:"ul"},"Updating properties and managing the model lifecycle")),(0,t.yg)("p",null,"The example shows both basic patterns for getting started and advanced patterns for production ML systems.")),(0,t.yg)("h2",{id:"code-examples"},"Code Examples"),(0,t.yg)("h3",{id:"querying-ml-model-information"},"Querying ML Model Information"),(0,t.yg)("p",null,"The standard REST APIs can be used to retrieve ML Model entities and their aspects:"),(0,t.yg)("details",null,(0,t.yg)("summary",null,"Python: Query an ML Model via REST API"),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre",className:"language-python"},'import urllib.parse\n\nimport requests\n\ngms_server = "http://localhost:8080"\n\nmodel_urn = "urn:li:mlModel:(urn:li:dataPlatform:mlflow,customer-churn-predictor,PROD)"\nencoded_urn = urllib.parse.quote(model_urn, safe="")\n\nresponse = requests.get(f"{gms_server}/entities/{encoded_urn}")\n\nif response.status_code == 200:\n    entity = response.json()\n\n    print(f"Entity URN: {entity[\'urn\']}")\n    print("\\nAspects:")\n\n    if "mlModelProperties" in entity["aspects"]:\n        props = entity["aspects"]["mlModelProperties"]\n        print(f"  Name: {props.get(\'name\')}")\n        print(f"  Description: {props.get(\'description\')}")\n        print(f"  Type: {props.get(\'type\')}")\n\n        if props.get("hyperParams"):\n            print("\\n  Hyperparameters:")\n            for param in props["hyperParams"]:\n                print(f"    - {param[\'name\']}: {param[\'value\']}")\n\n        if props.get("trainingMetrics"):\n            print("\\n  Training Metrics:")\n            for metric in props["trainingMetrics"]:\n                print(f"    - {metric[\'name\']}: {metric[\'value\']}")\n\n    if "globalTags" in entity["aspects"]:\n        tags = entity["aspects"]["globalTags"]["tags"]\n        print(f"\\n  Tags: {[tag[\'tag\'] for tag in tags]}")\n\n    if "ownership" in entity["aspects"]:\n        owners = entity["aspects"]["ownership"]["owners"]\n        print(f"\\n  Owners: {[owner[\'owner\'] for owner in owners]}")\n\n    if "intendedUse" in entity["aspects"]:\n        intended = entity["aspects"]["intendedUse"]\n        print(f"\\n  Primary Uses: {intended.get(\'primaryUses\')}")\n        print(f"  Out of Scope Uses: {intended.get(\'outOfScopeUses\')}")\n\nelse:\n    print(f"Failed to fetch entity: {response.status_code}")\n    print(response.text)\n\n'))),(0,t.yg)("h2",{id:"integration-points"},"Integration Points"),(0,t.yg)("h3",{id:"related-entities"},"Related Entities"),(0,t.yg)("p",null,"ML Models integrate with several other entities in the DataHub metadata model:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"mlModelGroup"),": Logical grouping of related model versions (e.g., all versions of a recommendation model)"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"mlModelDeployment"),": Running instances of deployed models with status, endpoint URLs, and deployment metadata"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"mlFeature"),": Individual features consumed by the model for inference"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"mlFeatureTable"),": Collections of features, often from feature stores"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"dataset"),": Training and evaluation datasets used by the model"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"dataProcessInstance")," (with ",(0,t.yg)("inlineCode",{parentName:"li"},"MLFLOW_TRAINING_RUN")," subtype): Specific training runs that created model versions, including metrics, hyperparameters, and lineage to input/output datasets"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"container")," (with ",(0,t.yg)("inlineCode",{parentName:"li"},"MLFLOW_EXPERIMENT")," subtype): Experiments that organize related training runs for a model or project"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"versionSet"),": Groups all versions of a model together for version management")),(0,t.yg)("h3",{id:"graphql-resolvers"},"GraphQL Resolvers"),(0,t.yg)("p",null,"The GraphQL API provides rich querying capabilities for ML Models through resolvers in ",(0,t.yg)("inlineCode",{parentName:"p"},"datahub-graphql-core/src/main/java/com/linkedin/datahub/graphql/types/mlmodel/"),". These resolvers support:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},"Fetching model details with all aspects"),(0,t.yg)("li",{parentName:"ul"},"Navigating relationships to features, groups, and deployments"),(0,t.yg)("li",{parentName:"ul"},"Searching and filtering models by tags, terms, platform, etc.")),(0,t.yg)("h3",{id:"ingestion-sources"},"Ingestion Sources"),(0,t.yg)("p",null,"Several ingestion sources automatically extract ML Model metadata:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"MLflow"),": Extracts registered models, versions, metrics, parameters, and lineage from MLflow tracking servers"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"SageMaker"),": Ingests models, model packages, and endpoints from AWS SageMaker"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Vertex AI"),": Extracts models and endpoints from Google Cloud Vertex AI"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Databricks"),": Ingests MLflow models from Databricks workspaces"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Unity Catalog"),": Extracts ML models registered in Unity Catalog")),(0,t.yg)("p",null,"These sources are located in ",(0,t.yg)("inlineCode",{parentName:"p"},"/metadata-ingestion/src/datahub/ingestion/source/")," and automatically populate model properties, relationships, and lineage."),(0,t.yg)("h2",{id:"notable-exceptions"},"Notable Exceptions"),(0,t.yg)("h3",{id:"model-versioning"},"Model Versioning"),(0,t.yg)("p",null,"ML Model versioning in DataHub uses the ",(0,t.yg)("inlineCode",{parentName:"p"},"versionProperties")," aspect, which provides a robust framework for tracking model versions across their lifecycle. This is the standard approach demonstrated in production ML platforms."),(0,t.yg)("h4",{id:"version-properties-aspect"},"Version Properties Aspect"),(0,t.yg)("p",null,"Every ML Model should use the ",(0,t.yg)("inlineCode",{parentName:"p"},"versionProperties")," aspect, which includes:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"version"),": A ",(0,t.yg)("inlineCode",{parentName:"li"},"VersionTagClass"),' containing the version identifier (e.g., "1", "2", "v1.0.0")'),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"versionSet"),": A URN that groups all versions of a model together (e.g., ",(0,t.yg)("inlineCode",{parentName:"li"},"urn:li:versionSet:(mlModel,mlmodel_my-model_versions)"),")"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"sortId"),": A string used for ordering versions (typically the version number zero-padded)"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"aliases"),": Optional array of ",(0,t.yg)("inlineCode",{parentName:"li"},"VersionTagClass")," objects for named version references")),(0,t.yg)("h4",{id:"version-aliases-for-ab-testing"},"Version Aliases for A/B Testing"),(0,t.yg)("p",null,"Version aliases enable flexible model lifecycle management and A/B testing workflows. Common aliases include:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},'"champion"'),": The currently deployed production model"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},'"challenger"'),": A candidate model being tested or evaluated"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},'"baseline"'),": A reference model for performance comparison"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},'"latest"'),": The most recently trained version")),(0,t.yg)("p",null,"These aliases allow you to reference models by their role rather than specific version numbers, enabling smooth model promotion workflows:"),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre"},'Model v1 (alias: "champion")     # Currently in production\nModel v2 (alias: "challenger")   # Being tested in canary deployment\nModel v3 (alias: "latest")       # Just completed training\n')),(0,t.yg)("p",null,"When v2 proves superior, you can update aliases without changing infrastructure:"),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre"},'Model v1 (no alias)              # Retired\nModel v2 (alias: "champion")     # Promoted to production\nModel v3 (alias: "challenger")   # Now being tested\n')),(0,t.yg)("h4",{id:"model-groups-and-versioning"},"Model Groups and Versioning"),(0,t.yg)("p",null,"Model groups (",(0,t.yg)("inlineCode",{parentName:"p"},"mlModelGroup")," entities) serve as logical containers for organizing related models. While model groups can contain multiple versions of the same model, versioning is handled through the ",(0,t.yg)("inlineCode",{parentName:"p"},"versionProperties")," aspect on individual models, not through the group structure itself. Model groups are used for:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},"Organizing all versions of a model family"),(0,t.yg)("li",{parentName:"ul"},"Grouping experimental variants or different architectures solving the same problem"),(0,t.yg)("li",{parentName:"ul"},"Managing lineage and metadata common across multiple related models")),(0,t.yg)("p",null,"The relationship between models and model groups is through the ",(0,t.yg)("inlineCode",{parentName:"p"},"groups")," field in ",(0,t.yg)("inlineCode",{parentName:"p"},"mlModelProperties"),", creating a ",(0,t.yg)("inlineCode",{parentName:"p"},"MemberOf")," relationship."),(0,t.yg)("h3",{id:"platform-specific-naming"},"Platform-Specific Naming"),(0,t.yg)("p",null,"Different ML platforms have different naming conventions:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"MLflow"),": Uses a two-level hierarchy (registered model name + version number). In DataHub, each version can be a separate entity, or versions can be tracked in a single entity."),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"SageMaker"),": Has multiple model concepts (model, model package, model package group). DataHub can model these as separate entities or consolidate them."),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"Vertex AI"),": Uses fully qualified resource names. These should be simplified to human-readable names when possible.")),(0,t.yg)("p",null,"When ingesting from these platforms, connectors handle platform-specific naming and convert it to appropriate DataHub URNs."),(0,t.yg)("h3",{id:"model-cards"},"Model Cards"),(0,t.yg)("p",null,"The various aspects (",(0,t.yg)("inlineCode",{parentName:"p"},"intendedUse"),", ",(0,t.yg)("inlineCode",{parentName:"p"},"mlModelFactorPrompts"),", ",(0,t.yg)("inlineCode",{parentName:"p"},"mlModelEthicalConsiderations"),", etc.) follow the Model Cards for Model Reporting framework (Mitchell et al., 2019). While these aspects are optional, they are strongly recommended for production models to ensure responsible AI practices and transparent model documentation."),(0,t.yg)("h2",{id:"technical-reference"},"Technical Reference"),(0,t.yg)("p",null,"For technical details about fields, searchability, and relationships, view the ",(0,t.yg)("strong",{parentName:"p"},"Columns")," tab in DataHub."))}g.isMDXComponent=!0}}]);