"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[66326],{15680:(e,t,a)=>{a.d(t,{xA:()=>p,yg:()=>d});var r=a(96540);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},i=Object.keys(e);for(r=0;r<i.length;r++)a=i[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)a=i[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var l=r.createContext({}),u=function(e){var t=r.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},p=function(e){var t=u(e.components);return r.createElement(l.Provider,{value:t},e.children)},g="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},y=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,i=e.originalType,l=e.parentName,p=o(e,["components","mdxType","originalType","parentName"]),g=u(a),y=n,d=g["".concat(l,".").concat(y)]||g[y]||m[y]||i;return a?r.createElement(d,s(s({ref:t},p),{},{components:a})):r.createElement(d,s({ref:t},p))}));function d(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=a.length,s=new Array(i);s[0]=y;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o[g]="string"==typeof e?e:n,s[1]=o;for(var u=2;u<i;u++)s[u]=a[u];return r.createElement.apply(null,s)}return r.createElement.apply(null,a)}y.displayName="MDXCreateElement"},1371:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>d,frontMatter:()=>o,metadata:()=>u,toc:()=>g});a(96540);var r=a(15680);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){return t=null!=t?t:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):function(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))})),e}function s(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},i=Object.keys(e);for(r=0;r<i.length;r++)a=i[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)a=i[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}const o={sidebar_position:31,title:"Query",slug:"/generated/metamodel/entities/query-datahub",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/generated/metamodel/entities/query-datahub.md"},l="Query",u={unversionedId:"docs/generated/metamodel/entities/query-datahub",id:"docs/generated/metamodel/entities/query-datahub",title:"Query",description:"The query entity represents SQL queries (or queries in other languages) that have been executed against one or more data assets such as datasets, tables, or views. Query entities capture both manually created queries and queries discovered through automated crawling of query logs from data platforms like BigQuery, Snowflake, Redshift, and others.",source:"@site/genDocs/docs/generated/metamodel/entities/query-datahub.md",sourceDirName:"docs/generated/metamodel/entities",slug:"/generated/metamodel/entities/query-datahub",permalink:"/docs/generated/metamodel/entities/query-datahub",draft:!1,editUrl:"https://github.com/datahub-project/datahub/blob/master/docs/generated/metamodel/entities/query-datahub.md",tags:[],version:"current",sidebarPosition:31,frontMatter:{sidebar_position:31,title:"Query",slug:"/generated/metamodel/entities/query-datahub",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/generated/metamodel/entities/query-datahub.md"},sidebar:"overviewSidebar",previous:{title:"ER Model Relationship",permalink:"/docs/generated/metamodel/entities/ermodelrelationship"},next:{title:"Query",permalink:"/docs/generated/metamodel/entities/query"}},p={},g=[{value:"Identity",id:"identity",level:2},{value:"Important Capabilities",id:"important-capabilities",level:2},{value:"Query Properties",id:"query-properties",level:3},{value:"Query Subjects",id:"query-subjects",level:3},{value:"Query Usage Statistics",id:"query-usage-statistics",level:3},{value:"Tags and Glossary Terms",id:"tags-and-glossary-terms",level:3},{value:"Adding Tags to a Query",id:"adding-tags-to-a-query",level:4},{value:"Adding Glossary Terms to a Query",id:"adding-glossary-terms-to-a-query",level:4},{value:"Ownership",id:"ownership",level:3},{value:"Platform Instance",id:"platform-instance",level:3},{value:"Integration Points",id:"integration-points",level:2},{value:"Relationship with Datasets",id:"relationship-with-datasets",level:3},{value:"Lineage Integration",id:"lineage-integration",level:3},{value:"Ingestion Sources",id:"ingestion-sources",level:3},{value:"GraphQL API",id:"graphql-api",level:3},{value:"Usage Analytics",id:"usage-analytics",level:3},{value:"Notable Exceptions",id:"notable-exceptions",level:2},{value:"Query Deduplication",id:"query-deduplication",level:3},{value:"Temporary Tables",id:"temporary-tables",level:3},{value:"Query Size Limits",id:"query-size-limits",level:3},{value:"Language Support",id:"language-support",level:3},{value:"Manual vs System Queries",id:"manual-vs-system-queries",level:3},{value:"Technical Reference",id:"technical-reference",level:2}],m={toc:g},y="wrapper";function d(e){var{components:t}=e,a=s(e,["components"]);return(0,r.yg)(y,i(function(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{},r=Object.keys(a);"function"==typeof Object.getOwnPropertySymbols&&(r=r.concat(Object.getOwnPropertySymbols(a).filter((function(e){return Object.getOwnPropertyDescriptor(a,e).enumerable})))),r.forEach((function(t){n(e,t,a[t])}))}return e}({},m,a),{components:t,mdxType:"MDXLayout"}),(0,r.yg)("h1",{id:"query"},"Query"),(0,r.yg)("p",null,"The query entity represents SQL queries (or queries in other languages) that have been executed against one or more data assets such as datasets, tables, or views. Query entities capture both manually created queries and queries discovered through automated crawling of query logs from data platforms like BigQuery, Snowflake, Redshift, and others."),(0,r.yg)("p",null,"Queries are powerful building blocks for understanding data lineage, usage patterns, and relationships between datasets. When DataHub ingests query logs from data warehouses, it automatically creates query entities that capture the SQL statements, the datasets they reference, execution statistics, and usage patterns over time."),(0,r.yg)("h2",{id:"identity"},"Identity"),(0,r.yg)("p",null,"Query entities are identified by a single piece of information:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"A unique identifier (",(0,r.yg)("inlineCode",{parentName:"li"},"id"),") that serves as the key for the query entity. This identifier is typically generated as a hash of the normalized query text, ensuring that identical queries are deduplicated and treated as the same entity.")),(0,r.yg)("p",null,"An example of a query identifier is ",(0,r.yg)("inlineCode",{parentName:"p"},"urn:li:query:3b8d7b8c7e4e8b4e3c2e1a5c6d7e8f9a"),". The identifier is a unique string that can be generated through various means:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"A hash of the normalized SQL query text (common for system-discovered queries)"),(0,r.yg)("li",{parentName:"ul"},"A user-provided identifier (for manually created queries)"),(0,r.yg)("li",{parentName:"ul"},"A platform-specific query identifier")),(0,r.yg)("h2",{id:"important-capabilities"},"Important Capabilities"),(0,r.yg)("h3",{id:"query-properties"},"Query Properties"),(0,r.yg)("p",null,"The ",(0,r.yg)("inlineCode",{parentName:"p"},"queryProperties")," aspect contains the core information about a query:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Statement"),": The actual query text and its language (SQL, or UNKNOWN)"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Source"),": How the query was discovered (",(0,r.yg)("inlineCode",{parentName:"li"},"MANUAL")," for user-entered queries via UI, or ",(0,r.yg)("inlineCode",{parentName:"li"},"SYSTEM")," for queries discovered by crawlers)"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Name"),": Optional display name to identify the query in a human-readable way"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Description"),": Optional description providing context about what the query does"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Created/Modified"),": Audit stamps tracking who created and last modified the query, along with timestamps"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Origin"),": The source entity that this query came from (e.g., a View, Stored Procedure, dbt Model, etc.)"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Custom Properties"),": Additional key-value pairs for platform-specific metadata")),(0,r.yg)("p",null,"The following code snippet shows you how to create a query entity with properties."),(0,r.yg)("details",null,(0,r.yg)("summary",null,"Python SDK: Create a query with properties"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'# metadata-ingestion/examples/library/query_create.py\nimport logging\nimport os\nimport time\n\nfrom datahub.emitter.mcp import MetadataChangeProposalWrapper\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\nfrom datahub.metadata.schema_classes import (\n    AuditStampClass,\n    QueryLanguageClass,\n    QueryPropertiesClass,\n    QuerySourceClass,\n    QueryStatementClass,\n    QuerySubjectClass,\n    QuerySubjectsClass,\n)\nfrom datahub.metadata.urns import CorpUserUrn, DatasetUrn, QueryUrn\n\nlog = logging.getLogger(__name__)\nlogging.basicConfig(level=logging.INFO)\n\nquery_id = "my-unique-query-id"\nquery_urn = QueryUrn(query_id)\n\ncurrent_timestamp = int(time.time() * 1000)\nactor_urn = CorpUserUrn("datahub")\n\nquery_properties = QueryPropertiesClass(\n    statement=QueryStatementClass(\n        value="SELECT customer_id, order_total FROM orders WHERE order_date >= \'2024-01-01\'",\n        language=QueryLanguageClass.SQL,\n    ),\n    source=QuerySourceClass.MANUAL,\n    name="Customer Orders Q1 2024",\n    description="Query to retrieve all customer orders from Q1 2024 for reporting",\n    created=AuditStampClass(time=current_timestamp, actor=actor_urn.urn()),\n    lastModified=AuditStampClass(time=current_timestamp, actor=actor_urn.urn()),\n)\n\ndataset_urn = DatasetUrn.from_string(\n    "urn:li:dataset:(urn:li:dataPlatform:postgres,public.orders,PROD)"\n)\nquery_subjects = QuerySubjectsClass(\n    subjects=[\n        QuerySubjectClass(entity=dataset_urn.urn()),\n    ]\n)\n\ngms_server = os.getenv("DATAHUB_GMS_URL", "http://localhost:8080")\ntoken = os.getenv("DATAHUB_GMS_TOKEN")\nrest_emitter = DatahubRestEmitter(gms_server=gms_server, token=token)\n\nmcpw_properties = MetadataChangeProposalWrapper(\n    entityUrn=query_urn.urn(),\n    aspect=query_properties,\n)\nrest_emitter.emit(mcpw_properties)\n\nmcpw_subjects = MetadataChangeProposalWrapper(\n    entityUrn=query_urn.urn(),\n    aspect=query_subjects,\n)\nrest_emitter.emit(mcpw_subjects)\n\nlog.info(f"Created query {query_urn}")\n\n'))),(0,r.yg)("p",null,"You can also update specific properties of an existing query:"),(0,r.yg)("details",null,(0,r.yg)("summary",null,"Python SDK: Update query properties"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'# metadata-ingestion/examples/library/query_update_properties.py\nimport logging\nimport time\n\nfrom datahub.emitter.mcp import MetadataChangeProposalWrapper\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\nfrom datahub.ingestion.graph.client import DataHubGraph, DataHubGraphConfig\nfrom datahub.metadata.schema_classes import (\n    AuditStampClass,\n    QueryPropertiesClass,\n)\nfrom datahub.metadata.urns import CorpUserUrn, QueryUrn\n\nlog = logging.getLogger(__name__)\nlogging.basicConfig(level=logging.INFO)\n\nquery_urn = QueryUrn("my-unique-query-id")\n\ngraph = DataHubGraph(DataHubGraphConfig(server="http://localhost:8080"))\nemitter = DatahubRestEmitter(gms_server="http://localhost:8080")\n\nexisting_properties = graph.get_aspect(\n    entity_urn=query_urn.urn(),\n    aspect_type=QueryPropertiesClass,\n)\n\nif not existing_properties:\n    log.error(f"Query {query_urn} does not exist or has no properties")\n    exit(1)\n\ncurrent_timestamp = int(time.time() * 1000)\nactor_urn = CorpUserUrn("datahub")\n\nexisting_properties.name = "Updated Query Name"\nexisting_properties.description = "This query has been updated with new documentation"\nexisting_properties.lastModified = AuditStampClass(\n    time=current_timestamp, actor=actor_urn.urn()\n)\n\nevent = MetadataChangeProposalWrapper(\n    entityUrn=query_urn.urn(),\n    aspect=existing_properties,\n)\n\nemitter.emit(event)\nlog.info(f"Updated properties for query {query_urn}")\n\n'))),(0,r.yg)("h3",{id:"query-subjects"},"Query Subjects"),(0,r.yg)("p",null,"The ",(0,r.yg)("inlineCode",{parentName:"p"},"querySubjects")," aspect captures the data assets that are referenced by a query. These are the datasets, tables, views, or other entities that the query reads from or writes to."),(0,r.yg)("p",null,"In single-asset queries (e.g., ",(0,r.yg)("inlineCode",{parentName:"p"},"SELECT * FROM table"),"), the subjects will contain a single table reference. In multi-asset queries (e.g., joins across multiple tables), the subjects may contain multiple table references."),(0,r.yg)("details",null,(0,r.yg)("summary",null,"Python SDK: Add subjects to a query"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'# metadata-ingestion/examples/library/query_add_subjects.py\nimport logging\n\nfrom datahub.emitter.mcp import MetadataChangeProposalWrapper\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\nfrom datahub.ingestion.graph.client import DataHubGraph, DataHubGraphConfig\nfrom datahub.metadata.schema_classes import QuerySubjectClass, QuerySubjectsClass\nfrom datahub.metadata.urns import DatasetUrn, QueryUrn\n\nlog = logging.getLogger(__name__)\nlogging.basicConfig(level=logging.INFO)\n\nquery_urn = QueryUrn("my-unique-query-id")\n\ngraph = DataHubGraph(DataHubGraphConfig(server="http://localhost:8080"))\nemitter = DatahubRestEmitter(gms_server="http://localhost:8080")\n\nexisting_subjects = graph.get_aspect(\n    entity_urn=query_urn.urn(),\n    aspect_type=QuerySubjectsClass,\n)\n\nsubjects = existing_subjects.subjects if existing_subjects else []\n\nnew_dataset_urn = DatasetUrn.from_string(\n    "urn:li:dataset:(urn:li:dataPlatform:postgres,public.customers,PROD)"\n)\nnew_subject = QuerySubjectClass(entity=new_dataset_urn.urn())\n\nif new_subject not in subjects:\n    subjects.append(new_subject)\n\nquery_subjects_aspect = QuerySubjectsClass(subjects=subjects)\n\nevent = MetadataChangeProposalWrapper(\n    entityUrn=query_urn.urn(),\n    aspect=query_subjects_aspect,\n)\n\nemitter.emit(event)\nlog.info(f"Added subject to query {query_urn}")\n\n'))),(0,r.yg)("h3",{id:"query-usage-statistics"},"Query Usage Statistics"),(0,r.yg)("p",null,"The ",(0,r.yg)("inlineCode",{parentName:"p"},"queryUsageStatistics")," aspect is a timeseries aspect that tracks execution statistics and usage patterns for queries over time. This includes:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Query Count"),": Total number of times the query was executed in a time bucket"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Query Cost"),": The compute cost associated with executing the query (platform-specific)"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Last Executed At"),": Timestamp of the most recent execution"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Unique User Count"),": Number of distinct users who executed the query"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"User Counts"),": Breakdown of execution counts by individual users")),(0,r.yg)("p",null,"This aspect is typically populated automatically by ingestion connectors that process query logs from data platforms. The timeseries nature allows for tracking trends and patterns in query usage over time."),(0,r.yg)("h3",{id:"tags-and-glossary-terms"},"Tags and Glossary Terms"),(0,r.yg)("p",null,'Like other DataHub entities, queries can have Tags or Terms attached to them. Tags are informal labels for categorizing queries (e.g., "production", "experimental", "deprecated"), while Terms are formal vocabulary from a business glossary (e.g., "Customer Data", "Financial Reporting").'),(0,r.yg)("h4",{id:"adding-tags-to-a-query"},"Adding Tags to a Query"),(0,r.yg)("p",null,"Tags are added to queries using the ",(0,r.yg)("inlineCode",{parentName:"p"},"globalTags")," aspect."),(0,r.yg)("details",null,(0,r.yg)("summary",null,"Python SDK: Add a tag to a query"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'# metadata-ingestion/examples/library/query_add_tag.py\nimport logging\n\nfrom datahub.emitter.mce_builder import make_tag_urn\nfrom datahub.emitter.mcp import MetadataChangeProposalWrapper\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\nfrom datahub.ingestion.graph.client import DataHubGraph, DataHubGraphConfig\nfrom datahub.metadata.schema_classes import GlobalTagsClass, TagAssociationClass\nfrom datahub.metadata.urns import QueryUrn\n\nlog = logging.getLogger(__name__)\nlogging.basicConfig(level=logging.INFO)\n\nquery_urn = QueryUrn("my-unique-query-id")\n\ngraph = DataHubGraph(DataHubGraphConfig(server="http://localhost:8080"))\nemitter = DatahubRestEmitter(gms_server="http://localhost:8080")\n\nexisting_tags = graph.get_aspect(\n    entity_urn=query_urn.urn(),\n    aspect_type=GlobalTagsClass,\n)\n\ntags_to_add = existing_tags.tags if existing_tags else []\n\ntags_to_add.append(\n    TagAssociationClass(tag=make_tag_urn("production"), context="Query categorization")\n)\n\nglobal_tags_aspect = GlobalTagsClass(tags=tags_to_add)\n\nevent = MetadataChangeProposalWrapper(\n    entityUrn=query_urn.urn(),\n    aspect=global_tags_aspect,\n)\n\nemitter.emit(event)\nlog.info(f"Added tag to query {query_urn}")\n\n'))),(0,r.yg)("h4",{id:"adding-glossary-terms-to-a-query"},"Adding Glossary Terms to a Query"),(0,r.yg)("p",null,"Terms are added using the ",(0,r.yg)("inlineCode",{parentName:"p"},"glossaryTerms")," aspect."),(0,r.yg)("details",null,(0,r.yg)("summary",null,"Python SDK: Add a term to a query"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'# metadata-ingestion/examples/library/query_add_term.py\nimport logging\n\nfrom datahub.emitter.mce_builder import make_term_urn\nfrom datahub.emitter.mcp import MetadataChangeProposalWrapper\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\nfrom datahub.ingestion.graph.client import DataHubGraph, DataHubGraphConfig\nfrom datahub.metadata.schema_classes import (\n    AuditStampClass,\n    GlossaryTermAssociationClass,\n    GlossaryTermsClass,\n)\nfrom datahub.metadata.urns import QueryUrn\n\nlog = logging.getLogger(__name__)\nlogging.basicConfig(level=logging.INFO)\n\nquery_urn = QueryUrn("my-unique-query-id")\n\ngraph = DataHubGraph(DataHubGraphConfig(server="http://localhost:8080"))\nemitter = DatahubRestEmitter(gms_server="http://localhost:8080")\n\nexisting_terms = graph.get_aspect(\n    entity_urn=query_urn.urn(),\n    aspect_type=GlossaryTermsClass,\n)\n\nterms_to_add = existing_terms.terms if existing_terms else []\n\nterms_to_add.append(\n    GlossaryTermAssociationClass(\n        urn=make_term_urn("CustomerData"), context="Query subject area"\n    )\n)\n\nglossary_terms_aspect = GlossaryTermsClass(\n    terms=terms_to_add,\n    auditStamp=AuditStampClass(time=0, actor="urn:li:corpuser:datahub"),\n)\n\nevent = MetadataChangeProposalWrapper(\n    entityUrn=query_urn.urn(),\n    aspect=glossary_terms_aspect,\n)\n\nemitter.emit(event)\nlog.info(f"Added glossary term to query {query_urn}")\n\n'))),(0,r.yg)("h3",{id:"ownership"},"Ownership"),(0,r.yg)("p",null,"Ownership is associated to a query using the ",(0,r.yg)("inlineCode",{parentName:"p"},"ownership")," aspect. Owners can be of different types such as ",(0,r.yg)("inlineCode",{parentName:"p"},"TECHNICAL_OWNER"),", ",(0,r.yg)("inlineCode",{parentName:"p"},"BUSINESS_OWNER"),", ",(0,r.yg)("inlineCode",{parentName:"p"},"DATA_STEWARD"),", etc. Ownership helps identify who is responsible for maintaining and understanding specific queries."),(0,r.yg)("details",null,(0,r.yg)("summary",null,"Python SDK: Add an owner to a query"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'# metadata-ingestion/examples/library/query_add_owner.py\nimport logging\n\nfrom datahub.emitter.mcp import MetadataChangeProposalWrapper\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\nfrom datahub.ingestion.graph.client import DataHubGraph, DataHubGraphConfig\nfrom datahub.metadata.schema_classes import (\n    OwnerClass,\n    OwnershipClass,\n    OwnershipTypeClass,\n)\nfrom datahub.metadata.urns import CorpUserUrn, QueryUrn\n\nlog = logging.getLogger(__name__)\nlogging.basicConfig(level=logging.INFO)\n\nquery_urn = QueryUrn("my-unique-query-id")\n\ngraph = DataHubGraph(DataHubGraphConfig(server="http://localhost:8080"))\nemitter = DatahubRestEmitter(gms_server="http://localhost:8080")\n\nexisting_ownership = graph.get_aspect(\n    entity_urn=query_urn.urn(),\n    aspect_type=OwnershipClass,\n)\n\nowners = existing_ownership.owners if existing_ownership else []\n\nnew_owner = OwnerClass(\n    owner=CorpUserUrn("jdoe").urn(),\n    type=OwnershipTypeClass.TECHNICAL_OWNER,\n)\n\nif new_owner not in owners:\n    owners.append(new_owner)\n\nownership_aspect = OwnershipClass(\n    owners=owners,\n)\n\nevent = MetadataChangeProposalWrapper(\n    entityUrn=query_urn.urn(),\n    aspect=ownership_aspect,\n)\n\nemitter.emit(event)\nlog.info(f"Added owner to query {query_urn}")\n\n'))),(0,r.yg)("h3",{id:"platform-instance"},"Platform Instance"),(0,r.yg)("p",null,"The ",(0,r.yg)("inlineCode",{parentName:"p"},"dataPlatformInstance")," aspect allows you to specify which specific instance of a data platform the query is associated with. This is useful when you have multiple instances of the same platform (e.g., multiple Snowflake accounts or BigQuery projects)."),(0,r.yg)("h2",{id:"integration-points"},"Integration Points"),(0,r.yg)("h3",{id:"relationship-with-datasets"},"Relationship with Datasets"),(0,r.yg)("p",null,"Queries have a fundamental relationship with dataset entities through the ",(0,r.yg)("inlineCode",{parentName:"p"},"querySubjects")," aspect. Each subject in a query references a dataset URN, creating a bidirectional relationship that allows you to:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"Navigate from a query to the datasets it references"),(0,r.yg)("li",{parentName:"ul"},"Navigate from a dataset to all queries that reference it")),(0,r.yg)("p",null,"This relationship is crucial for understanding dataset usage and query-based lineage."),(0,r.yg)("h3",{id:"lineage-integration"},"Lineage Integration"),(0,r.yg)("p",null,"Queries play a central role in DataHub's lineage capabilities:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},(0,r.yg)("strong",{parentName:"p"},"Query-based Lineage"),": When DataHub processes SQL queries (either from query logs or manually provided), it performs SQL parsing to extract column-level lineage information. This lineage is then attached to datasets, showing how data flows from source columns to destination columns through SQL transformations.")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},(0,r.yg)("strong",{parentName:"p"},"Fine-grained Lineage"),": Queries can be referenced in fine-grained lineage edges on datasets, providing the SQL context for how specific columns are derived. The query URN is stored in the ",(0,r.yg)("inlineCode",{parentName:"p"},"query")," field of fine-grained lineage information.")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},(0,r.yg)("strong",{parentName:"p"},"Origin Tracking"),": Queries can have an ",(0,r.yg)("inlineCode",{parentName:"p"},"origin")," field pointing to the entity they came from (e.g., a View or Stored Procedure), creating a traceable chain from the query execution back to its source definition."))),(0,r.yg)("h3",{id:"ingestion-sources"},"Ingestion Sources"),(0,r.yg)("p",null,"Several DataHub ingestion connectors automatically discover and create query entities:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"BigQuery"),": Extracts queries from audit logs and information schema"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Snowflake"),": Processes query history from account usage views"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Redshift"),": Reads from system tables like ",(0,r.yg)("inlineCode",{parentName:"li"},"STL_QUERY")," and ",(0,r.yg)("inlineCode",{parentName:"li"},"SVL_QUERY")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"SQL Queries Source"),": A generic connector that can process query logs from any SQL database"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Mode"),": Extracts queries from Mode reports and analyses"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Hex"),": Discovers queries from Hex notebook cells")),(0,r.yg)("p",null,"These connectors typically:"),(0,r.yg)("ol",null,(0,r.yg)("li",{parentName:"ol"},"Fetch query logs with SQL statements and metadata"),(0,r.yg)("li",{parentName:"ol"},"Parse the SQL to identify referenced tables"),(0,r.yg)("li",{parentName:"ol"},"Create query entities with appropriate properties and subjects"),(0,r.yg)("li",{parentName:"ol"},"Generate usage statistics as timeseries data"),(0,r.yg)("li",{parentName:"ol"},"Emit column-level lineage derived from SQL parsing")),(0,r.yg)("h3",{id:"graphql-api"},"GraphQL API"),(0,r.yg)("p",null,"Queries can be created, updated, and deleted through the DataHub GraphQL API:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"createQuery"),": Creates a new query with specified properties and subjects"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"updateQuery"),": Updates an existing query's name, description, or statement"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"deleteQuery"),": Soft-deletes a query entity")),(0,r.yg)("p",null,"These mutations are available through the GraphQL endpoint and are used by the DataHub UI for manual query management."),(0,r.yg)("h3",{id:"usage-analytics"},"Usage Analytics"),(0,r.yg)("p",null,"Query entities contribute to dataset usage analytics. When query usage statistics are ingested, they:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"Increment the dataset's usage counts"),(0,r.yg)("li",{parentName:"ul"},"Track which users are querying which datasets"),(0,r.yg)("li",{parentName:"ul"},"Provide insights into query patterns and frequency"),(0,r.yg)("li",{parentName:"ul"},"Help identify high-value datasets based on query activity")),(0,r.yg)("h2",{id:"notable-exceptions"},"Notable Exceptions"),(0,r.yg)("h3",{id:"query-deduplication"},"Query Deduplication"),(0,r.yg)("p",null,"Queries are automatically deduplicated based on their normalized query text. This means that:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"Whitespace differences are ignored"),(0,r.yg)("li",{parentName:"ul"},"Comments are typically removed during normalization"),(0,r.yg)("li",{parentName:"ul"},"Identical queries from different users or time periods are merged into a single query entity"),(0,r.yg)("li",{parentName:"ul"},"Usage statistics are aggregated across all executions of the same normalized query")),(0,r.yg)("p",null,"This deduplication is essential for managing the volume of queries in large-scale deployments."),(0,r.yg)("h3",{id:"temporary-tables"},"Temporary Tables"),(0,r.yg)("p",null,"When processing queries that involve temporary tables, the SQL parsing aggregator maintains session context to:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"Track temporary table creation and usage within a session"),(0,r.yg)("li",{parentName:"ul"},"Resolve lineage through temporary tables to underlying permanent tables"),(0,r.yg)("li",{parentName:"ul"},"Avoid creating query subjects that reference ephemeral temporary tables")),(0,r.yg)("p",null,"This ensures that query lineage reflects the actual data dependencies rather than intermediate temporary structures."),(0,r.yg)("h3",{id:"query-size-limits"},"Query Size Limits"),(0,r.yg)("p",null,"Very large query statements (e.g., generated queries with thousands of lines) may be truncated or rejected to maintain system performance. The exact limits depend on the backend configuration and the storage layer."),(0,r.yg)("h3",{id:"language-support"},"Language Support"),(0,r.yg)("p",null,"Currently, query entities primarily support SQL as the query language. While there is an ",(0,r.yg)("inlineCode",{parentName:"p"},"UNKNOWN")," language option, DataHub's SQL parsing and lineage extraction capabilities are specifically designed for SQL dialects. Other query languages (e.g., Cypher, SPARQL, or proprietary query languages) can be stored but will not benefit from automatic lineage extraction."),(0,r.yg)("h3",{id:"manual-vs-system-queries"},"Manual vs System Queries"),(0,r.yg)("p",null,"Queries can have two sources:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"MANUAL"),": Queries created by users through the DataHub UI or API"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"SYSTEM"),": Queries discovered automatically by ingestion connectors")),(0,r.yg)("p",null,"This distinction helps differentiate between user-curated queries (which might be documented and named) and the potentially large volume of queries automatically discovered from query logs."),(0,r.yg)("h2",{id:"technical-reference"},"Technical Reference"),(0,r.yg)("p",null,"For technical details about fields, searchability, and relationships, view the ",(0,r.yg)("strong",{parentName:"p"},"Columns")," tab in DataHub."))}d.isMDXComponent=!0}}]);