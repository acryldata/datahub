"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[90490],{15680:(e,n,t)=>{t.d(n,{xA:()=>m,yg:()=>u});var a=t(96540);function l(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function r(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){l(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function i(e,n){if(null==e)return{};var t,a,l=function(e,n){if(null==e)return{};var t,a,l={},o=Object.keys(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||(l[t]=e[t]);return l}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(l[t]=e[t])}return l}var s=a.createContext({}),p=function(e){var n=a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):r(r({},n),e)),t},m=function(e){var n=p(e.components);return a.createElement(s.Provider,{value:n},e.children)},d="mdxType",y={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},g=a.forwardRef((function(e,n){var t=e.components,l=e.mdxType,o=e.originalType,s=e.parentName,m=i(e,["components","mdxType","originalType","parentName"]),d=p(t),g=l,u=d["".concat(s,".").concat(g)]||d[g]||y[g]||o;return t?a.createElement(u,r(r({ref:n},m),{},{components:t})):a.createElement(u,r({ref:n},m))}));function u(e,n){var t=arguments,l=n&&n.mdxType;if("string"==typeof e||l){var o=t.length,r=new Array(o);r[0]=g;var i={};for(var s in n)hasOwnProperty.call(n,s)&&(i[s]=n[s]);i.originalType=e,i[d]="string"==typeof e?e:l,r[1]=i;for(var p=2;p<o;p++)r[p]=t[p];return a.createElement.apply(null,r)}return a.createElement.apply(null,t)}g.displayName="MDXCreateElement"},98810:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>m,contentTitle:()=>s,default:()=>u,frontMatter:()=>i,metadata:()=>p,toc:()=>d});t(96540);var a=t(15680);function l(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){return n=null!=n?n:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):function(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))})),e}function r(e,n){if(null==e)return{};var t,a,l=function(e,n){if(null==e)return{};var t,a,l={},o=Object.keys(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||(l[t]=e[t]);return l}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(l[t]=e[t])}return l}const i={sidebar_position:19,title:"ML Model Deployment",slug:"/generated/metamodel/entities/mlmodeldeployment-datahub",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/generated/metamodel/entities/mlModelDeployment-datahub.md"},s="ML Model Deployment",p={unversionedId:"docs/generated/metamodel/entities/mlModelDeployment-datahub",id:"docs/generated/metamodel/entities/mlModelDeployment-datahub",title:"ML Model Deployment",description:"ML Model Deployments represent deployed instances of machine learning models running in production or other environments. They track the operational aspects of ML models, including their deployment status, platform, configuration, and lifecycle. Model deployments are distinct from ML models themselves - while an ML model represents the trained artifact, a deployment represents a specific instance of that model serving predictions in a particular environment.",source:"@site/genDocs/docs/generated/metamodel/entities/mlModelDeployment-datahub.md",sourceDirName:"docs/generated/metamodel/entities",slug:"/generated/metamodel/entities/mlmodeldeployment-datahub",permalink:"/docs/generated/metamodel/entities/mlmodeldeployment-datahub",draft:!1,editUrl:"https://github.com/datahub-project/datahub/blob/master/docs/generated/metamodel/entities/mlModelDeployment-datahub.md",tags:[],version:"current",sidebarPosition:19,frontMatter:{sidebar_position:19,title:"ML Model Deployment",slug:"/generated/metamodel/entities/mlmodeldeployment-datahub",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/generated/metamodel/entities/mlModelDeployment-datahub.md"},sidebar:"overviewSidebar",previous:{title:"ML Model Group",permalink:"/docs/generated/metamodel/entities/mlmodelgroup"},next:{title:"ML Model Deployment",permalink:"/docs/generated/metamodel/entities/mlmodeldeployment"}},m={},d=[{value:"Identity",id:"identity",level:2},{value:"Important Capabilities",id:"important-capabilities",level:2},{value:"Deployment Properties",id:"deployment-properties",level:3},{value:"Linking Deployments to Models",id:"linking-deployments-to-models",level:3},{value:"Tags and Classification",id:"tags-and-classification",level:3},{value:"Ownership",id:"ownership",level:3},{value:"Platform Instance",id:"platform-instance",level:3},{value:"Deprecation and Lifecycle Management",id:"deprecation-and-lifecycle-management",level:3},{value:"Organizational Context",id:"organizational-context",level:3},{value:"Containers",id:"containers",level:4},{value:"Integration with External Systems",id:"integration-with-external-systems",level:2},{value:"Ingestion from ML Platforms",id:"ingestion-from-ml-platforms",level:3},{value:"Querying Deployment Information",id:"querying-deployment-information",level:3},{value:"Relationships API",id:"relationships-api",level:3},{value:"Notable Exceptions",id:"notable-exceptions",level:2},{value:"Deployment vs Model Distinction",id:"deployment-vs-model-distinction",level:3},{value:"Multiple Deployments per Model",id:"multiple-deployments-per-model",level:3},{value:"Ephemeral Deployments",id:"ephemeral-deployments",level:3},{value:"Platform-Specific Deployment Concepts",id:"platform-specific-deployment-concepts",level:3},{value:"Related Entities",id:"related-entities",level:2},{value:"Technical Reference",id:"technical-reference",level:2}],y={toc:d},g="wrapper";function u(e){var{components:n}=e,t=r(e,["components"]);return(0,a.yg)(g,o(function(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{},a=Object.keys(t);"function"==typeof Object.getOwnPropertySymbols&&(a=a.concat(Object.getOwnPropertySymbols(t).filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable})))),a.forEach((function(n){l(e,n,t[n])}))}return e}({},y,t),{components:n,mdxType:"MDXLayout"}),(0,a.yg)("h1",{id:"ml-model-deployment"},"ML Model Deployment"),(0,a.yg)("p",null,"ML Model Deployments represent deployed instances of machine learning models running in production or other environments. They track the operational aspects of ML models, including their deployment status, platform, configuration, and lifecycle. Model deployments are distinct from ML models themselves - while an ML model represents the trained artifact, a deployment represents a specific instance of that model serving predictions in a particular environment."),(0,a.yg)("h2",{id:"identity"},"Identity"),(0,a.yg)("p",null,"ML Model Deployments are identified by three pieces of information:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"The platform where the deployment is hosted"),": This is the specific deployment or serving platform that hosts the model. Examples include ",(0,a.yg)("inlineCode",{parentName:"li"},"sagemaker"),", ",(0,a.yg)("inlineCode",{parentName:"li"},"azureml"),", ",(0,a.yg)("inlineCode",{parentName:"li"},"vertexai"),", ",(0,a.yg)("inlineCode",{parentName:"li"},"mlflow"),", ",(0,a.yg)("inlineCode",{parentName:"li"},"seldon"),", ",(0,a.yg)("inlineCode",{parentName:"li"},"kserve"),", etc. This corresponds to a data platform URN."),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"The name of the deployment"),": Each platform has its own way of naming deployments. For example, SageMaker uses endpoint names, while Azure ML uses deployment names within a workspace."),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"The environment or origin"),": This qualifier indicates the environment where the deployment runs (PROD, DEV, TEST, etc.), similar to the fabric concept used for datasets.")),(0,a.yg)("p",null,"An example of an ML model deployment identifier is ",(0,a.yg)("inlineCode",{parentName:"p"},"urn:li:mlModelDeployment:(urn:li:dataPlatform:sagemaker,recommendation-endpoint,PROD)"),"."),(0,a.yg)("h2",{id:"important-capabilities"},"Important Capabilities"),(0,a.yg)("h3",{id:"deployment-properties"},"Deployment Properties"),(0,a.yg)("p",null,"The core metadata about a deployment is stored in the ",(0,a.yg)("inlineCode",{parentName:"p"},"mlModelDeploymentProperties")," aspect. This includes:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Description"),": Documentation explaining the purpose and configuration of the deployment"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Deployment Status"),": The current operational state of the deployment, which can be:",(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"IN_SERVICE"),": Active deployments serving predictions"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"OUT_OF_SERVICE"),": Deployments that are not currently serving traffic"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"CREATING"),": Deployments being provisioned"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"UPDATING"),": Deployments being updated with new configurations"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"ROLLING_BACK"),": Deployments being reverted to a previous version"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"DELETING"),": Deployments being removed"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"FAILED"),": Deployments in an error state"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"UNKNOWN"),": Deployments with unmapped or unknown status"))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Version"),": The version of the deployment configuration"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Created At"),": Timestamp indicating when the deployment was created"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Custom Properties"),": Additional platform-specific configuration details"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"External URL"),": Link to view the deployment in its native platform")),(0,a.yg)("p",null,"The following code snippet shows you how to create an ML model deployment."),(0,a.yg)("details",null,(0,a.yg)("summary",null,"Python SDK: Create an ML model deployment"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'import os\n\nimport datahub.emitter.mce_builder as builder\nimport datahub.metadata.schema_classes as models\nfrom datahub.emitter.mcp import MetadataChangeProposalWrapper\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\n\n# Get DataHub connection details from environment\ngms_server = os.getenv("DATAHUB_GMS_URL", "http://localhost:8080")\ntoken = os.getenv("DATAHUB_GMS_TOKEN")\n\n# Create a deployment URN - the unique identifier for the ML model deployment\ndeployment_urn = builder.make_ml_model_deployment_urn(\n    platform="sagemaker",\n    deployment_name="recommendation-endpoint",\n    env="PROD",\n)\n\n# Define deployment properties with status and custom properties\ndeployment_properties = models.MLModelDeploymentPropertiesClass(\n    description="Production deployment of recommendation model on SageMaker",\n    customProperties={\n        "instance_type": "ml.m5.xlarge",\n        "instance_count": "3",\n        "endpoint_config": "recommendation-endpoint-config-v1",\n    },\n    externalUrl="https://console.aws.amazon.com/sagemaker/home#/endpoints/recommendation-endpoint",\n    status=models.DeploymentStatusClass.IN_SERVICE,\n)\n\n# Create a metadata change proposal\nevent = MetadataChangeProposalWrapper(\n    entityUrn=deployment_urn,\n    aspect=deployment_properties,\n)\n\n# Emit the metadata\nrest_emitter = DatahubRestEmitter(gms_server=gms_server, token=token)\nrest_emitter.emit(event)\nprint(f"Created ML model deployment: {deployment_urn}")\n\n'))),(0,a.yg)("h3",{id:"linking-deployments-to-models"},"Linking Deployments to Models"),(0,a.yg)("p",null,"ML Model Deployments are connected to their underlying ML Models through the ",(0,a.yg)("inlineCode",{parentName:"p"},"mlModelProperties.deployments")," field. This relationship enables:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Deployment Tracking"),": Understanding where and how a model is deployed"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Version Management"),": Tracking which model version is deployed in each environment"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Impact Analysis"),": Understanding the production footprint of a model"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Rollback Planning"),": Identifying active deployments when model issues arise")),(0,a.yg)("details",null,(0,a.yg)("summary",null,"Python SDK: Link a deployment to an ML model"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'from datahub.emitter import mce_builder\nfrom datahub.metadata.urns import MlModelUrn\nfrom datahub.sdk import DataHubClient\n\nclient = DataHubClient.from_env()\n\nmlmodel_urn = MlModelUrn(platform="sagemaker", name="recommendation-model")\n\ndeployment_urn = mce_builder.make_ml_model_deployment_urn(\n    platform="sagemaker",\n    deployment_name="recommendation-endpoint",\n    env="PROD",\n)\n\nmlmodel = client.entities.get(mlmodel_urn)\nmlmodel.add_deployment(deployment_urn)\n\nclient.entities.update(mlmodel)\n\n'))),(0,a.yg)("h3",{id:"tags-and-classification"},"Tags and Classification"),(0,a.yg)("p",null,"ML Model Deployments can have tags attached to them using the ",(0,a.yg)("inlineCode",{parentName:"p"},"globalTags")," aspect. Tags are useful for:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Categorizing deployments by purpose (production, canary, shadow)"),(0,a.yg)("li",{parentName:"ul"},"Tracking cost centers or teams"),(0,a.yg)("li",{parentName:"ul"},"Marking deployments for compliance or security review"),(0,a.yg)("li",{parentName:"ul"},"Organizing deployments by model type or use case")),(0,a.yg)("h3",{id:"ownership"},"Ownership"),(0,a.yg)("p",null,"Ownership is associated with a deployment using the ",(0,a.yg)("inlineCode",{parentName:"p"},"ownership")," aspect. Owners can be technical owners (ML engineers, MLOps teams) or business owners (product managers, data scientists) who are responsible for the deployment. Ownership helps with:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Accountability for deployment health and performance"),(0,a.yg)("li",{parentName:"ul"},"Contact information for incidents"),(0,a.yg)("li",{parentName:"ul"},"Access control and permissions management"),(0,a.yg)("li",{parentName:"ul"},"Organizational governance")),(0,a.yg)("details",null,(0,a.yg)("summary",null,"Python SDK: Add an owner to a deployment"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'import datahub.emitter.mce_builder as builder\nimport datahub.metadata.schema_classes as models\nfrom datahub.emitter.mcp import MetadataChangeProposalWrapper\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\nfrom datahub.ingestion.graph.client import DatahubClientConfig, DataHubGraph\n\ngms_endpoint = "http://localhost:8080"\nemitter = DatahubRestEmitter(gms_server=gms_endpoint, extra_headers={})\ngraph = DataHubGraph(DatahubClientConfig(server=gms_endpoint))\n\ndeployment_urn = builder.make_ml_model_deployment_urn(\n    platform="sagemaker",\n    deployment_name="recommendation-endpoint",\n    env="PROD",\n)\n\nowner_to_add = builder.make_user_urn("mlops_team")\n\ncurrent_ownership = graph.get_aspect(\n    entity_urn=deployment_urn, aspect_type=models.OwnershipClass\n)\n\nif current_ownership:\n    if owner_to_add not in [owner.owner for owner in current_ownership.owners]:\n        current_ownership.owners.append(\n            models.OwnerClass(\n                owner=owner_to_add,\n                type=models.OwnershipTypeClass.TECHNICAL_OWNER,\n            )\n        )\nelse:\n    current_ownership = models.OwnershipClass(\n        owners=[\n            models.OwnerClass(\n                owner=owner_to_add,\n                type=models.OwnershipTypeClass.TECHNICAL_OWNER,\n            )\n        ]\n    )\n\nemitter.emit(\n    MetadataChangeProposalWrapper(\n        entityUrn=deployment_urn,\n        aspect=current_ownership,\n    )\n)\n\n'))),(0,a.yg)("h3",{id:"platform-instance"},"Platform Instance"),(0,a.yg)("p",null,"The ",(0,a.yg)("inlineCode",{parentName:"p"},"dataPlatformInstance")," aspect provides additional context about the specific instance of the deployment platform. This is important when organizations have multiple instances of the same platform (e.g., multiple SageMaker accounts, different Azure ML workspaces, separate Kubernetes clusters)."),(0,a.yg)("h3",{id:"deprecation-and-lifecycle-management"},"Deprecation and Lifecycle Management"),(0,a.yg)("p",null,"Deployments can be marked as deprecated using the ",(0,a.yg)("inlineCode",{parentName:"p"},"deprecation")," aspect when they are planned for decommissioning. This includes:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Deprecation Flag"),": Marking the deployment as deprecated"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Decommission Time"),": Planned date for removing the deployment"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Deprecation Note"),": Information about why the deployment is being deprecated and what replaces it"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Replacement"),": Reference to the new deployment that should be used instead")),(0,a.yg)("p",null,"The ",(0,a.yg)("inlineCode",{parentName:"p"},"status")," aspect can also be used to soft-delete a deployment (mark it as removed) when it has been taken down but you want to preserve the historical metadata."),(0,a.yg)("h3",{id:"organizational-context"},"Organizational Context"),(0,a.yg)("h4",{id:"containers"},"Containers"),(0,a.yg)("p",null,"Deployments can belong to a parent container (such as an ML workspace, namespace, or project) using the ",(0,a.yg)("inlineCode",{parentName:"p"},"container")," aspect. This creates a hierarchical structure:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},"ML Workspace (Container)\n\u251c\u2500\u2500 Model Deployment 1\n\u251c\u2500\u2500 Model Deployment 2\n\u2514\u2500\u2500 Model Deployment 3\n")),(0,a.yg)("p",null,"This hierarchy helps with:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Organizing deployments by project or team"),(0,a.yg)("li",{parentName:"ul"},"Managing access control at the workspace level"),(0,a.yg)("li",{parentName:"ul"},"Understanding resource utilization and costs"),(0,a.yg)("li",{parentName:"ul"},"Navigating related deployments")),(0,a.yg)("h2",{id:"integration-with-external-systems"},"Integration with External Systems"),(0,a.yg)("h3",{id:"ingestion-from-ml-platforms"},"Ingestion from ML Platforms"),(0,a.yg)("p",null,"ML Model Deployments are typically ingested automatically from ML platforms using DataHub's ingestion connectors:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"SageMaker"),": Ingests endpoint deployments with their configuration and status"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Azure ML"),": Ingests model deployments from workspaces"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Vertex AI"),": Ingests endpoint deployments from Google Cloud"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"MLflow"),": Ingests registered model deployments"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Seldon Core / KServe"),": Ingests inference services from Kubernetes")),(0,a.yg)("p",null,"Each connector maps platform-specific deployment metadata to DataHub's standardized deployment model."),(0,a.yg)("h3",{id:"querying-deployment-information"},"Querying Deployment Information"),(0,a.yg)("p",null,"You can retrieve deployment information using DataHub's REST API:"),(0,a.yg)("details",null,(0,a.yg)("summary",null,"Fetch deployment entity snapshot"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-bash"},"curl 'http://localhost:8080/entities/urn%3Ali%3AmlModelDeployment%3A(urn%3Ali%3AdataPlatform%3Asagemaker,recommendation-endpoint,PROD)'\n")),(0,a.yg)("p",null,"The response includes all aspects of the deployment, including:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Deployment properties (status, version, description)"),(0,a.yg)("li",{parentName:"ul"},"Ownership information"),(0,a.yg)("li",{parentName:"ul"},"Tags and classification"),(0,a.yg)("li",{parentName:"ul"},"Platform instance details"),(0,a.yg)("li",{parentName:"ul"},"Deprecation status"))),(0,a.yg)("h3",{id:"relationships-api"},"Relationships API"),(0,a.yg)("p",null,"You can query deployment relationships to understand its connections to other entities:"),(0,a.yg)("details",null,(0,a.yg)("summary",null,"Find deployments for a specific ML model"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-bash"},"curl 'http://localhost:8080/relationships?direction=INCOMING&urn=urn%3Ali%3AmlModel%3A(urn%3Ali%3AdataPlatform%3Asagemaker,recommendation-model,PROD)&types=DeployedTo'\n")),(0,a.yg)("p",null,"This returns all deployments of the specified ML model.")),(0,a.yg)("details",null,(0,a.yg)("summary",null,"Find the ML model for a deployment"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-bash"},"curl 'http://localhost:8080/relationships?direction=OUTGOING&urn=urn%3Ali%3AmlModel%3A(urn%3Ali%3AdataPlatform%3Asagemaker,recommendation-model,PROD)&types=DeployedTo'\n")),(0,a.yg)("p",null,"This returns the ML model that is deployed to the specified deployment.")),(0,a.yg)("h2",{id:"notable-exceptions"},"Notable Exceptions"),(0,a.yg)("h3",{id:"deployment-vs-model-distinction"},"Deployment vs Model Distinction"),(0,a.yg)("p",null,"It's important to understand the distinction between ML Models and ML Model Deployments:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},(0,a.yg)("strong",{parentName:"p"},"ML Model"),": Represents the trained model artifact, including training data, metrics, hyperparameters, and model metadata. A model can have multiple versions and can exist independently of any deployment.")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},(0,a.yg)("strong",{parentName:"p"},"ML Model Deployment"),": Represents a running instance of a model serving predictions. A deployment references a specific model version and includes operational metadata like status, configuration, and serving platform details."))),(0,a.yg)("p",null,"This separation enables:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Tracking the same model deployed to multiple environments (dev, staging, prod)"),(0,a.yg)("li",{parentName:"ul"},"Understanding deployment history and rollbacks"),(0,a.yg)("li",{parentName:"ul"},"Managing the operational lifecycle independently from model development"),(0,a.yg)("li",{parentName:"ul"},"Supporting A/B testing and canary deployments of the same model")),(0,a.yg)("h3",{id:"multiple-deployments-per-model"},"Multiple Deployments per Model"),(0,a.yg)("p",null,"A single ML model can have multiple deployments simultaneously:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Different environments (production, staging, development)"),(0,a.yg)("li",{parentName:"ul"},"Different regions (US, EU, Asia)"),(0,a.yg)("li",{parentName:"ul"},"Different configurations (batch vs real-time, different instance types)"),(0,a.yg)("li",{parentName:"ul"},"A/B testing scenarios (challenger vs champion)")),(0,a.yg)("p",null,"Each deployment is tracked as a separate entity with its own metadata."),(0,a.yg)("h3",{id:"ephemeral-deployments"},"Ephemeral Deployments"),(0,a.yg)("p",null,"Some platforms create temporary or ephemeral deployments (e.g., for batch inference jobs). These deployments may have short lifespans but are still valuable to track for:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Cost attribution"),(0,a.yg)("li",{parentName:"ul"},"Compliance and audit trails"),(0,a.yg)("li",{parentName:"ul"},"Understanding model usage patterns"),(0,a.yg)("li",{parentName:"ul"},"Debugging and troubleshooting")),(0,a.yg)("h3",{id:"platform-specific-deployment-concepts"},"Platform-Specific Deployment Concepts"),(0,a.yg)("p",null,"Different ML platforms have varying concepts that map to deployments:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"SageMaker Endpoints"),": Real-time inference endpoints with one or more model variants"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Azure ML Online Endpoints"),": Managed endpoints with blue-green deployment support"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Vertex AI Endpoints"),": Deployed models with traffic splitting capabilities"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Kubernetes Inference Services"),": Pod-based model serving with auto-scaling")),(0,a.yg)("p",null,"DataHub's deployment model abstracts these platform differences while preserving important platform-specific details in custom properties."),(0,a.yg)("h2",{id:"related-entities"},"Related Entities"),(0,a.yg)("p",null,"ML Model Deployments frequently interact with these other DataHub entities:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"MLModel"),": The underlying trained model that is deployed"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"MLModelGroup"),": A collection of related models that may share deployment infrastructure"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"DataPlatform"),": The platform hosting the deployment (SageMaker, Azure ML, etc.)"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Container"),": The workspace, namespace, or project containing the deployment"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"CorpUser / CorpGroup"),": Owners and operators of the deployment"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Tag"),": Classification and organizational tags"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"DataPlatformInstance"),": The specific instance of the deployment platform")),(0,a.yg)("h2",{id:"technical-reference"},"Technical Reference"),(0,a.yg)("p",null,"For technical details about fields, searchability, and relationships, view the ",(0,a.yg)("strong",{parentName:"p"},"Columns")," tab in DataHub."))}u.isMDXComponent=!0}}]);