"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[51955],{15680:(e,t,a)=>{a.d(t,{xA:()=>u,yg:()=>y});var n=a(96540);function s(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){s(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,s=function(e,t){if(null==e)return{};var a,n,s={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(s[a]=e[a]);return s}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(s[a]=e[a])}return s}var l=n.createContext({}),p=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},u=function(e){var t=p(e.components);return n.createElement(l.Provider,{value:t},e.children)},m="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},g=n.forwardRef((function(e,t){var a=e.components,s=e.mdxType,i=e.originalType,l=e.parentName,u=o(e,["components","mdxType","originalType","parentName"]),m=p(a),g=s,y=m["".concat(l,".").concat(g)]||m[g]||d[g]||i;return a?n.createElement(y,r(r({ref:t},u),{},{components:a})):n.createElement(y,r({ref:t},u))}));function y(e,t){var a=arguments,s=t&&t.mdxType;if("string"==typeof e||s){var i=a.length,r=new Array(i);r[0]=g;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o[m]="string"==typeof e?e:s,r[1]=o;for(var p=2;p<i;p++)r[p]=a[p];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}g.displayName="MDXCreateElement"},5651:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>u,contentTitle:()=>l,default:()=>y,frontMatter:()=>o,metadata:()=>p,toc:()=>m});a(96540);var n=a(15680);function s(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){return t=null!=t?t:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):function(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))})),e}function r(e,t){if(null==e)return{};var a,n,s=function(e,t){if(null==e)return{};var a,n,s={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(s[a]=e[a]);return s}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(s[a]=e[a])}return s}const o={sidebar_position:16,title:"Assertion",slug:"/generated/metamodel/entities/assertion-datahub",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/generated/metamodel/entities/assertion-datahub.md"},l="Assertion",p={unversionedId:"docs/generated/metamodel/entities/assertion-datahub",id:"docs/generated/metamodel/entities/assertion-datahub",title:"Assertion",description:"The assertion entity represents a data quality rule that can be applied to one or more datasets. Assertions are the foundation of DataHub's data quality framework, enabling organizations to define, monitor, and enforce expectations about their data. They encompass various types of checks including field-level validation, volume monitoring, freshness tracking, schema validation, and custom SQL-based rules.",source:"@site/genDocs/docs/generated/metamodel/entities/assertion-datahub.md",sourceDirName:"docs/generated/metamodel/entities",slug:"/generated/metamodel/entities/assertion-datahub",permalink:"/docs/generated/metamodel/entities/assertion-datahub",draft:!1,editUrl:"https://github.com/datahub-project/datahub/blob/master/docs/generated/metamodel/entities/assertion-datahub.md",tags:[],version:"current",sidebarPosition:16,frontMatter:{sidebar_position:16,title:"Assertion",slug:"/generated/metamodel/entities/assertion-datahub",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/generated/metamodel/entities/assertion-datahub.md"},sidebar:"overviewSidebar",previous:{title:"GlossaryNode",permalink:"/docs/generated/metamodel/entities/glossarynode"},next:{title:"Assertion",permalink:"/docs/generated/metamodel/entities/assertion"}},u={},m=[{value:"Identity",id:"identity",level:2},{value:"Generating Stable Assertion IDs",id:"generating-stable-assertion-ids",level:3},{value:"Important Capabilities",id:"important-capabilities",level:2},{value:"Assertion Types",id:"assertion-types",level:3},{value:"1. Field Assertions (FIELD)",id:"1-field-assertions-field",level:4},{value:"2. Volume Assertions (VOLUME)",id:"2-volume-assertions-volume",level:4},{value:"3. Freshness Assertions (FRESHNESS)",id:"3-freshness-assertions-freshness",level:4},{value:"4. Schema Assertions (DATA_SCHEMA)",id:"4-schema-assertions-data_schema",level:4},{value:"5. SQL Assertions (SQL)",id:"5-sql-assertions-sql",level:4},{value:"6. Custom Assertions (CUSTOM)",id:"6-custom-assertions-custom",level:4},{value:"Assertion Source",id:"assertion-source",level:3},{value:"Assertion Run Events",id:"assertion-run-events",level:3},{value:"Assertion Actions",id:"assertion-actions",level:3},{value:"Tags and Metadata",id:"tags-and-metadata",level:3},{value:"Standard Operators and Parameters",id:"standard-operators-and-parameters",level:3},{value:"Standard Aggregations",id:"standard-aggregations",level:3},{value:"Integration Points",id:"integration-points",level:2},{value:"Relationship to Datasets",id:"relationship-to-datasets",level:3},{value:"Relationship to Data Jobs",id:"relationship-to-data-jobs",level:3},{value:"Relationship to Data Platforms",id:"relationship-to-data-platforms",level:3},{value:"GraphQL API",id:"graphql-api",level:3},{value:"Integration with dbt",id:"integration-with-dbt",level:3},{value:"Integration with Great Expectations",id:"integration-with-great-expectations",level:3},{value:"Integration with Snowflake Data Quality",id:"integration-with-snowflake-data-quality",level:3},{value:"Notable Exceptions",id:"notable-exceptions",level:2},{value:"Legacy Dataset Assertion Type",id:"legacy-dataset-assertion-type",level:3},{value:"Assertion Results vs. Assertion Metrics",id:"assertion-results-vs-assertion-metrics",level:3},{value:"Assertion Scheduling",id:"assertion-scheduling",level:3},{value:"Assertion vs. Test Results",id:"assertion-vs-test-results",level:3},{value:"Technical Reference",id:"technical-reference",level:2}],d={toc:m},g="wrapper";function y(e){var{components:t}=e,a=r(e,["components"]);return(0,n.yg)(g,i(function(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{},n=Object.keys(a);"function"==typeof Object.getOwnPropertySymbols&&(n=n.concat(Object.getOwnPropertySymbols(a).filter((function(e){return Object.getOwnPropertyDescriptor(a,e).enumerable})))),n.forEach((function(t){s(e,t,a[t])}))}return e}({},d,a),{components:t,mdxType:"MDXLayout"}),(0,n.yg)("h1",{id:"assertion"},"Assertion"),(0,n.yg)("p",null,"The assertion entity represents a data quality rule that can be applied to one or more datasets. Assertions are the foundation of DataHub's data quality framework, enabling organizations to define, monitor, and enforce expectations about their data. They encompass various types of checks including field-level validation, volume monitoring, freshness tracking, schema validation, and custom SQL-based rules."),(0,n.yg)("p",null,"Assertions can originate from multiple sources: they can be defined natively within DataHub, ingested from external data quality tools (such as Great Expectations, dbt tests, or Snowflake Data Quality), or inferred by ML-based systems. Each assertion tracks its evaluation history over time, maintaining a complete audit trail of passes, failures, and errors."),(0,n.yg)("h2",{id:"identity"},"Identity"),(0,n.yg)("p",null,"An ",(0,n.yg)("strong",{parentName:"p"},"Assertion")," is uniquely identified by an ",(0,n.yg)("inlineCode",{parentName:"p"},"assertionId"),", which is a globally unique identifier that remains constant across runs of the assertion. The URN format is:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre"},"urn:li:assertion:<assertionId>\n")),(0,n.yg)("p",null,"The ",(0,n.yg)("inlineCode",{parentName:"p"},"assertionId")," is typically a generated GUID that uniquely identifies the assertion definition. For example:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre"},"urn:li:assertion:432475190cc846f2894b5b3aa4d55af2\n")),(0,n.yg)("h3",{id:"generating-stable-assertion-ids"},"Generating Stable Assertion IDs"),(0,n.yg)("p",null,"The logic for generating stable assertion IDs differs based on the source of the assertion:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Native Assertions"),": Created in DataHub Cloud's UI or API, the platform generates a UUID"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"External Assertions"),": Each integration tool generates IDs based on its own conventions:",(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Great Expectations"),": Combines expectation suite name, expectation type, and parameters"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"dbt Tests"),": Uses the test's unique_id from the manifest"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Snowflake Data Quality"),": Uses the native DMF rule ID"))),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Inferred Assertions"),": ML-based systems generate IDs based on the inference model and target")),(0,n.yg)("p",null,"The key requirement is that the same assertion definition should always produce the same ",(0,n.yg)("inlineCode",{parentName:"p"},"assertionId"),", enabling DataHub to track the assertion's history over time even as it's re-evaluated."),(0,n.yg)("h2",{id:"important-capabilities"},"Important Capabilities"),(0,n.yg)("h3",{id:"assertion-types"},"Assertion Types"),(0,n.yg)("p",null,"DataHub supports several types of assertions, each designed to validate different aspects of data quality:"),(0,n.yg)("h4",{id:"1-field-assertions-field"},"1. Field Assertions (FIELD)"),(0,n.yg)("p",null,"Field assertions validate individual columns or fields within a dataset. They come in two sub-types:"),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Field Values Assertions"),": Validate that each value in a column meets certain criteria. For example:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Values must be within a specific range"),(0,n.yg)("li",{parentName:"ul"},"Values must match a regex pattern"),(0,n.yg)("li",{parentName:"ul"},"Values must be one of a set of allowed values"),(0,n.yg)("li",{parentName:"ul"},"Values must not be null")),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Field Metric Assertions"),": Validate aggregated statistics about a column. For example:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Null percentage must be less than 5%"),(0,n.yg)("li",{parentName:"ul"},"Unique count must equal row count (uniqueness check)"),(0,n.yg)("li",{parentName:"ul"},"Mean value must be between 0 and 100"),(0,n.yg)("li",{parentName:"ul"},"Standard deviation must be less than 10")),(0,n.yg)("details",null,(0,n.yg)("summary",null,"Python SDK: Create a field uniqueness assertion"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},'# metadata-ingestion/examples/library/assertion_field_uniqueness.py\nimport os\n\nimport datahub.emitter.mce_builder as builder\nfrom datahub.emitter.mcp import MetadataChangeProposalWrapper\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\nfrom datahub.metadata.schema_classes import (\n    AssertionInfoClass,\n    AssertionStdOperatorClass,\n    AssertionTypeClass,\n    FieldAssertionInfoClass,\n    FieldAssertionTypeClass,\n    FieldMetricAssertionClass,\n    FieldMetricTypeClass,\n    SchemaFieldSpecClass,\n)\n\nemitter = DatahubRestEmitter(\n    gms_server=os.getenv("DATAHUB_GMS_URL", "http://localhost:8080"),\n    token=os.getenv("DATAHUB_GMS_TOKEN"),\n)\n\ndataset_urn = builder.make_dataset_urn(platform="snowflake", name="mydb.myschema.users")\n\nfield_assertion_info = FieldAssertionInfoClass(\n    type=FieldAssertionTypeClass.FIELD_METRIC,\n    entity=dataset_urn,\n    fieldMetricAssertion=FieldMetricAssertionClass(\n        field=SchemaFieldSpecClass(\n            path="user_id",\n            type="VARCHAR",\n            nativeType="VARCHAR",\n        ),\n        metric=FieldMetricTypeClass.UNIQUE_COUNT,\n        operator=AssertionStdOperatorClass.EQUAL_TO,\n        parameters=None,\n    ),\n)\n\nassertion_info = AssertionInfoClass(\n    type=AssertionTypeClass.FIELD,\n    fieldAssertion=field_assertion_info,\n    description="User ID must be unique across all rows",\n)\n\nassertion_urn = builder.make_assertion_urn(\n    builder.datahub_guid(\n        {"entity": dataset_urn, "field": "user_id", "type": "uniqueness"}\n    )\n)\n\nassertion_info_mcp = MetadataChangeProposalWrapper(\n    entityUrn=assertion_urn,\n    aspect=assertion_info,\n)\n\nemitter.emit_mcp(assertion_info_mcp)\nprint(f"Created field uniqueness assertion: {assertion_urn}")\n\n'))),(0,n.yg)("h4",{id:"2-volume-assertions-volume"},"2. Volume Assertions (VOLUME)"),(0,n.yg)("p",null,"Volume assertions monitor the amount of data in a dataset. They support several sub-types:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"ROW_COUNT_TOTAL"),": Total number of rows must meet expectations"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"ROW_COUNT_CHANGE"),": Change in row count over time must meet expectations"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"INCREMENTING_SEGMENT_ROW_COUNT_TOTAL"),": Latest partition/segment row count"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"INCREMENTING_SEGMENT_ROW_COUNT_CHANGE"),": Change between consecutive partitions")),(0,n.yg)("p",null,"Volume assertions are critical for detecting data pipeline failures, incomplete loads, or unexpected data growth."),(0,n.yg)("details",null,(0,n.yg)("summary",null,"Python SDK: Create a row count volume assertion"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},'# metadata-ingestion/examples/library/assertion_volume_rows.py\nimport os\n\nimport datahub.emitter.mce_builder as builder\nfrom datahub.emitter.mcp import MetadataChangeProposalWrapper\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\nfrom datahub.metadata.schema_classes import (\n    AssertionInfoClass,\n    AssertionStdOperatorClass,\n    AssertionStdParameterClass,\n    AssertionStdParametersClass,\n    AssertionStdParameterTypeClass,\n    AssertionTypeClass,\n    RowCountTotalClass,\n    VolumeAssertionInfoClass,\n    VolumeAssertionTypeClass,\n)\n\nemitter = DatahubRestEmitter(\n    gms_server=os.getenv("DATAHUB_GMS_URL", "http://localhost:8080"),\n    token=os.getenv("DATAHUB_GMS_TOKEN"),\n)\n\ndataset_urn = builder.make_dataset_urn(\n    platform="bigquery", name="project.dataset.orders"\n)\n\nvolume_assertion_info = VolumeAssertionInfoClass(\n    type=VolumeAssertionTypeClass.ROW_COUNT_TOTAL,\n    entity=dataset_urn,\n    rowCountTotal=RowCountTotalClass(\n        operator=AssertionStdOperatorClass.BETWEEN,\n        parameters=AssertionStdParametersClass(\n            minValue=AssertionStdParameterClass(\n                type=AssertionStdParameterTypeClass.NUMBER,\n                value="1000",\n            ),\n            maxValue=AssertionStdParameterClass(\n                type=AssertionStdParameterTypeClass.NUMBER,\n                value="1000000",\n            ),\n        ),\n    ),\n)\n\nassertion_info = AssertionInfoClass(\n    type=AssertionTypeClass.VOLUME,\n    volumeAssertion=volume_assertion_info,\n    description="Orders table must contain between 1,000 and 1,000,000 rows",\n)\n\nassertion_urn = builder.make_assertion_urn(\n    builder.datahub_guid({"entity": dataset_urn, "type": "row-count-range"})\n)\n\nassertion_info_mcp = MetadataChangeProposalWrapper(\n    entityUrn=assertion_urn,\n    aspect=assertion_info,\n)\n\nemitter.emit_mcp(assertion_info_mcp)\nprint(f"Created volume assertion: {assertion_urn}")\n\n'))),(0,n.yg)("h4",{id:"3-freshness-assertions-freshness"},"3. Freshness Assertions (FRESHNESS)"),(0,n.yg)("p",null,"Freshness assertions ensure data is updated within expected time windows. Two types are supported:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"DATASET_CHANGE"),": Based on dataset change operations (insert, update, delete) captured from audit logs"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"DATA_JOB_RUN"),": Based on successful execution of a data job")),(0,n.yg)("p",null,"Freshness assertions define a schedule that specifies when updates should occur (e.g., daily by 9 AM, every 4 hours) and what tolerance is acceptable."),(0,n.yg)("details",null,(0,n.yg)("summary",null,"Python SDK: Create a dataset change freshness assertion"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},'# metadata-ingestion/examples/library/assertion_freshness.py\nimport os\n\nimport datahub.emitter.mce_builder as builder\nfrom datahub.emitter.mcp import MetadataChangeProposalWrapper\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\nfrom datahub.metadata.schema_classes import (\n    AssertionInfoClass,\n    AssertionTypeClass,\n    FreshnessAssertionInfoClass,\n    FreshnessAssertionScheduleClass,\n    FreshnessAssertionScheduleTypeClass,\n    FreshnessAssertionTypeClass,\n    FreshnessCronScheduleClass,\n)\n\nemitter = DatahubRestEmitter(\n    gms_server=os.getenv("DATAHUB_GMS_URL", "http://localhost:8080"),\n    token=os.getenv("DATAHUB_GMS_TOKEN"),\n)\n\ndataset_urn = builder.make_dataset_urn(\n    platform="redshift", name="prod.analytics.daily_metrics"\n)\n\nfreshness_assertion_info = FreshnessAssertionInfoClass(\n    type=FreshnessAssertionTypeClass.DATASET_CHANGE,\n    entity=dataset_urn,\n    schedule=FreshnessAssertionScheduleClass(\n        type=FreshnessAssertionScheduleTypeClass.CRON,\n        cron=FreshnessCronScheduleClass(\n            cron="0 9 * * *",\n            timezone="America/Los_Angeles",\n            windowStartOffsetMs=None,\n        ),\n    ),\n)\n\nassertion_info = AssertionInfoClass(\n    type=AssertionTypeClass.FRESHNESS,\n    freshnessAssertion=freshness_assertion_info,\n    description="Daily metrics table must be updated every day by 9 AM Pacific Time",\n)\n\nassertion_urn = builder.make_assertion_urn(\n    builder.datahub_guid({"entity": dataset_urn, "type": "freshness-daily-9am"})\n)\n\nassertion_info_mcp = MetadataChangeProposalWrapper(\n    entityUrn=assertion_urn,\n    aspect=assertion_info,\n)\n\nemitter.emit_mcp(assertion_info_mcp)\nprint(f"Created freshness assertion: {assertion_urn}")\n\n'))),(0,n.yg)("h4",{id:"4-schema-assertions-data_schema"},"4. Schema Assertions (DATA_SCHEMA)"),(0,n.yg)("p",null,"Schema assertions validate that a dataset's structure matches expectations. They verify:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Presence or absence of specific columns"),(0,n.yg)("li",{parentName:"ul"},"Column data types"),(0,n.yg)("li",{parentName:"ul"},"Column ordering (optional)"),(0,n.yg)("li",{parentName:"ul"},"Schema compatibility modes:",(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"EXACT_MATCH"),": Schema must match exactly"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"SUPERSET"),": Actual schema can have additional columns"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"SUBSET"),": Actual schema can have fewer columns")))),(0,n.yg)("p",null,"Schema assertions are valuable for detecting breaking changes in upstream data sources."),(0,n.yg)("details",null,(0,n.yg)("summary",null,"Python SDK: Create a schema assertion"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},'# metadata-ingestion/examples/library/assertion_schema.py\nimport os\nimport time\n\nimport datahub.emitter.mce_builder as builder\nfrom datahub.emitter.mcp import MetadataChangeProposalWrapper\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\nfrom datahub.metadata.schema_classes import (\n    AssertionInfoClass,\n    AssertionTypeClass,\n    AuditStampClass,\n    NumberTypeClass,\n    SchemaAssertionCompatibilityClass,\n    SchemaAssertionInfoClass,\n    SchemaFieldClass,\n    SchemaFieldDataTypeClass,\n    SchemalessClass,\n    SchemaMetadataClass,\n    StringTypeClass,\n)\n\nemitter = DatahubRestEmitter(\n    gms_server=os.getenv("DATAHUB_GMS_URL", "http://localhost:8080"),\n    token=os.getenv("DATAHUB_GMS_TOKEN"),\n)\n\ndataset_urn = builder.make_dataset_urn(platform="kafka", name="prod.user_events")\n\ncurrent_timestamp = int(time.time() * 1000)\naudit_stamp = AuditStampClass(\n    time=current_timestamp,\n    actor="urn:li:corpuser:datahub",\n)\n\nexpected_schema = SchemaMetadataClass(\n    schemaName="user_events",\n    platform=builder.make_data_platform_urn("kafka"),\n    version=0,\n    created=audit_stamp,\n    lastModified=audit_stamp,\n    fields=[\n        SchemaFieldClass(\n            fieldPath="user_id",\n            type=SchemaFieldDataTypeClass(type=StringTypeClass()),\n            nativeDataType="string",\n            lastModified=audit_stamp,\n        ),\n        SchemaFieldClass(\n            fieldPath="event_type",\n            type=SchemaFieldDataTypeClass(type=StringTypeClass()),\n            nativeDataType="string",\n            lastModified=audit_stamp,\n        ),\n        SchemaFieldClass(\n            fieldPath="timestamp",\n            type=SchemaFieldDataTypeClass(type=NumberTypeClass()),\n            nativeDataType="long",\n            lastModified=audit_stamp,\n        ),\n        SchemaFieldClass(\n            fieldPath="properties",\n            type=SchemaFieldDataTypeClass(type=StringTypeClass()),\n            nativeDataType="string",\n            lastModified=audit_stamp,\n        ),\n    ],\n    hash="",\n    platformSchema=SchemalessClass(),\n)\n\nschema_assertion_info = SchemaAssertionInfoClass(\n    entity=dataset_urn,\n    schema=expected_schema,\n    compatibility=SchemaAssertionCompatibilityClass.SUPERSET,\n)\n\nassertion_info = AssertionInfoClass(\n    type=AssertionTypeClass.DATA_SCHEMA,\n    schemaAssertion=schema_assertion_info,\n    description="User events stream must have required schema fields (can include additional fields)",\n)\n\nassertion_urn = builder.make_assertion_urn(\n    builder.datahub_guid({"entity": dataset_urn, "type": "schema-check"})\n)\n\nassertion_info_mcp = MetadataChangeProposalWrapper(\n    entityUrn=assertion_urn,\n    aspect=assertion_info,\n)\n\nemitter.emit_mcp(assertion_info_mcp)\nprint(f"Created schema assertion: {assertion_urn}")\n\n'))),(0,n.yg)("h4",{id:"5-sql-assertions-sql"},"5. SQL Assertions (SQL)"),(0,n.yg)("p",null,"SQL assertions allow custom validation logic using arbitrary SQL queries. Two types:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"METRIC"),": Execute SQL and assert the returned metric meets expectations"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"METRIC_CHANGE"),": Assert the change in a SQL metric over time")),(0,n.yg)("p",null,"SQL assertions provide maximum flexibility for complex validation scenarios that don't fit other assertion types, such as cross-table referential integrity checks or business rule validation."),(0,n.yg)("details",null,(0,n.yg)("summary",null,"Python SDK: Create a SQL metric assertion"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},'# metadata-ingestion/examples/library/assertion_sql_metric.py\nimport os\n\nimport datahub.emitter.mce_builder as builder\nfrom datahub.emitter.mcp import MetadataChangeProposalWrapper\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\nfrom datahub.metadata.schema_classes import (\n    AssertionInfoClass,\n    AssertionStdOperatorClass,\n    AssertionStdParameterClass,\n    AssertionStdParametersClass,\n    AssertionStdParameterTypeClass,\n    AssertionTypeClass,\n    SqlAssertionInfoClass,\n    SqlAssertionTypeClass,\n)\n\nemitter = DatahubRestEmitter(\n    gms_server=os.getenv("DATAHUB_GMS_URL", "http://localhost:8080"),\n    token=os.getenv("DATAHUB_GMS_TOKEN"),\n)\n\ndataset_urn = builder.make_dataset_urn(platform="postgres", name="public.transactions")\n\nsql_assertion_info = SqlAssertionInfoClass(\n    type=SqlAssertionTypeClass.METRIC,\n    entity=dataset_urn,\n    statement="SELECT SUM(amount) FROM public.transactions WHERE status = \'completed\' AND date = CURRENT_DATE",\n    operator=AssertionStdOperatorClass.GREATER_THAN_OR_EQUAL_TO,\n    parameters=AssertionStdParametersClass(\n        value=AssertionStdParameterClass(\n            type=AssertionStdParameterTypeClass.NUMBER,\n            value="0",\n        )\n    ),\n)\n\nassertion_info = AssertionInfoClass(\n    type=AssertionTypeClass.SQL,\n    sqlAssertion=sql_assertion_info,\n    description="Total completed transaction amount today must be non-negative",\n)\n\nassertion_urn = builder.make_assertion_urn(\n    builder.datahub_guid(\n        {"entity": dataset_urn, "type": "sql-completed-transactions-sum"}\n    )\n)\n\nassertion_info_mcp = MetadataChangeProposalWrapper(\n    entityUrn=assertion_urn,\n    aspect=assertion_info,\n)\n\nemitter.emit_mcp(assertion_info_mcp)\nprint(f"Created SQL assertion: {assertion_urn}")\n\n'))),(0,n.yg)("h4",{id:"6-custom-assertions-custom"},"6. Custom Assertions (CUSTOM)"),(0,n.yg)("p",null,"Custom assertions provide an extension point for assertion types not directly modeled in DataHub. They're useful when:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Integrating third-party data quality tools with unique assertion types"),(0,n.yg)("li",{parentName:"ul"},"Starting integration before fully mapping to DataHub's type system"),(0,n.yg)("li",{parentName:"ul"},"Implementing organization-specific validation logic")),(0,n.yg)("h3",{id:"assertion-source"},"Assertion Source"),(0,n.yg)("p",null,"The ",(0,n.yg)("inlineCode",{parentName:"p"},"assertionInfo")," aspect includes an ",(0,n.yg)("inlineCode",{parentName:"p"},"AssertionSource")," that identifies the origin of the assertion:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"NATIVE"),": Defined directly in DataHub (DataHub Cloud feature)"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"EXTERNAL"),": Ingested from external tools (Great Expectations, dbt, Snowflake, etc.)"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"INFERRED"),": Generated by ML-based inference systems (DataHub Cloud feature)")),(0,n.yg)("p",null,"External assertions should have a corresponding ",(0,n.yg)("inlineCode",{parentName:"p"},"dataPlatformInstance")," aspect that identifies the specific platform instance they originated from."),(0,n.yg)("h3",{id:"assertion-run-events"},"Assertion Run Events"),(0,n.yg)("p",null,"Assertion evaluations are tracked using the ",(0,n.yg)("inlineCode",{parentName:"p"},"assertionRunEvent")," timeseries aspect. Each evaluation creates a new event with:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"timestampMillis"),": When the evaluation occurred"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"runId"),": Platform-specific identifier for this evaluation run"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"asserteeUrn"),": The entity being asserted (typically a dataset)"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"assertionUrn"),": The assertion being evaluated"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"status"),": COMPLETE, RUNNING, or ERROR"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"result"),": SUCCESS, FAILURE, or ERROR with details"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"batchSpec"),": Optional information about the data batch evaluated"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"runtimeContext"),": Optional key-value pairs with runtime parameters")),(0,n.yg)("p",null,"Run events enable tracking assertion health over time, identifying trends, and debugging failures."),(0,n.yg)("h3",{id:"assertion-actions"},"Assertion Actions"),(0,n.yg)("p",null,"The ",(0,n.yg)("inlineCode",{parentName:"p"},"assertionActions")," aspect defines automated responses to assertion outcomes:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"onSuccess"),": Actions triggered when assertion passes"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"onFailure"),": Actions triggered when assertion fails")),(0,n.yg)("p",null,"Common actions include:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Sending notifications (email, Slack, PagerDuty)"),(0,n.yg)("li",{parentName:"ul"},"Creating incidents"),(0,n.yg)("li",{parentName:"ul"},"Triggering downstream workflows"),(0,n.yg)("li",{parentName:"ul"},"Updating metadata")),(0,n.yg)("h3",{id:"tags-and-metadata"},"Tags and Metadata"),(0,n.yg)("p",null,"Like other DataHub entities, assertions support standard metadata capabilities:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"globalTags"),": Categorize and organize assertions"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"glossaryTerms"),": Link assertions to business concepts"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"status"),": Mark assertions as active or deprecated")),(0,n.yg)("details",null,(0,n.yg)("summary",null,"Python SDK: Add tags to an assertion"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},'# metadata-ingestion/examples/library/assertion_add_tags.py\nimport datahub.emitter.mce_builder as builder\nfrom datahub.emitter.mcp import MetadataChangeProposalWrapper\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\nfrom datahub.ingestion.graph.client import DataHubGraph, DataHubGraphConfig\nfrom datahub.metadata.schema_classes import (\n    GlobalTagsClass,\n    TagAssociationClass,\n)\n\ngraph = DataHubGraph(DataHubGraphConfig(server="http://localhost:8080"))\nemitter = DatahubRestEmitter("http://localhost:8080")\n\nassertion_urn = "urn:li:assertion:432475190cc846f2894b5b3aa4d55af2"\n\nexisting_tags = graph.get_aspect(\n    entity_urn=assertion_urn,\n    aspect_type=GlobalTagsClass,\n)\n\nif existing_tags is None:\n    existing_tags = GlobalTagsClass(tags=[])\n\ntag_to_add = builder.make_tag_urn("data-quality")\n\ntag_association = TagAssociationClass(tag=tag_to_add)\n\nif tag_association not in existing_tags.tags:\n    existing_tags.tags.append(tag_association)\n\n    tags_mcp = MetadataChangeProposalWrapper(\n        entityUrn=assertion_urn,\n        aspect=existing_tags,\n    )\n\n    emitter.emit_mcp(tags_mcp)\n    print(f"Added tag \'{tag_to_add}\' to assertion {assertion_urn}")\nelse:\n    print(f"Tag \'{tag_to_add}\' already exists on assertion {assertion_urn}")\n\n'))),(0,n.yg)("h3",{id:"standard-operators-and-parameters"},"Standard Operators and Parameters"),(0,n.yg)("p",null,"Assertions use a standard set of operators for comparisons:"),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Numeric"),": ",(0,n.yg)("inlineCode",{parentName:"p"},"BETWEEN"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"LESS_THAN"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"LESS_THAN_OR_EQUAL_TO"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"GREATER_THAN"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"GREATER_THAN_OR_EQUAL_TO"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"EQUAL_TO"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"NOT_EQUAL_TO")),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"String"),": ",(0,n.yg)("inlineCode",{parentName:"p"},"CONTAIN"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"START_WITH"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"END_WITH"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"REGEX_MATCH"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"IN"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"NOT_IN")),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Boolean"),": ",(0,n.yg)("inlineCode",{parentName:"p"},"IS_TRUE"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"IS_FALSE"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"NULL"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"NOT_NULL")),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Native"),": ",(0,n.yg)("inlineCode",{parentName:"p"},"_NATIVE_")," for platform-specific operators"),(0,n.yg)("p",null,"Parameters are provided via ",(0,n.yg)("inlineCode",{parentName:"p"},"AssertionStdParameters"),":"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"value"),": Single value for most operators"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"minValue"),", ",(0,n.yg)("inlineCode",{parentName:"li"},"maxValue"),": Range endpoints for ",(0,n.yg)("inlineCode",{parentName:"li"},"BETWEEN")),(0,n.yg)("li",{parentName:"ul"},"Parameter types: ",(0,n.yg)("inlineCode",{parentName:"li"},"NUMBER"),", ",(0,n.yg)("inlineCode",{parentName:"li"},"STRING"),", ",(0,n.yg)("inlineCode",{parentName:"li"},"SET"))),(0,n.yg)("h3",{id:"standard-aggregations"},"Standard Aggregations"),(0,n.yg)("p",null,"Field and volume assertions can apply aggregation functions before evaluation:"),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Statistical"),": ",(0,n.yg)("inlineCode",{parentName:"p"},"MEAN"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"MEDIAN"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"STDDEV"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"MIN"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"MAX"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"SUM")),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Count-based"),": ",(0,n.yg)("inlineCode",{parentName:"p"},"ROW_COUNT"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"COLUMN_COUNT"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"UNIQUE_COUNT"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"NULL_COUNT")),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Proportional"),": ",(0,n.yg)("inlineCode",{parentName:"p"},"UNIQUE_PROPORTION"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"NULL_PROPORTION")),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Identity"),": ",(0,n.yg)("inlineCode",{parentName:"p"},"IDENTITY")," (no aggregation), ",(0,n.yg)("inlineCode",{parentName:"p"},"COLUMNS")," (all columns)"),(0,n.yg)("h2",{id:"integration-points"},"Integration Points"),(0,n.yg)("h3",{id:"relationship-to-datasets"},"Relationship to Datasets"),(0,n.yg)("p",null,"Assertions have a strong relationship with datasets through the ",(0,n.yg)("inlineCode",{parentName:"p"},"Asserts")," relationship:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Field assertions target specific dataset columns"),(0,n.yg)("li",{parentName:"ul"},"Volume assertions monitor dataset row counts"),(0,n.yg)("li",{parentName:"ul"},"Freshness assertions track dataset update times"),(0,n.yg)("li",{parentName:"ul"},"Schema assertions validate dataset structure"),(0,n.yg)("li",{parentName:"ul"},"SQL assertions query dataset contents")),(0,n.yg)("p",null,"Datasets maintain a reverse relationship, showing all assertions that validate them. This enables users to understand the quality checks applied to any dataset."),(0,n.yg)("h3",{id:"relationship-to-data-jobs"},"Relationship to Data Jobs"),(0,n.yg)("p",null,"Freshness assertions can target data jobs (pipelines) to ensure they execute on schedule. When a ",(0,n.yg)("inlineCode",{parentName:"p"},"FreshnessAssertionInfo")," has ",(0,n.yg)("inlineCode",{parentName:"p"},"type=DATA_JOB_RUN"),", the ",(0,n.yg)("inlineCode",{parentName:"p"},"entity")," field references a dataJob URN rather than a dataset."),(0,n.yg)("h3",{id:"relationship-to-data-platforms"},"Relationship to Data Platforms"),(0,n.yg)("p",null,"External assertions maintain a relationship to their source platform through the ",(0,n.yg)("inlineCode",{parentName:"p"},"dataPlatformInstance")," aspect. This enables:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Filtering assertions by source tool"),(0,n.yg)("li",{parentName:"ul"},"Deep-linking back to the source platform"),(0,n.yg)("li",{parentName:"ul"},"Understanding the assertion's external context")),(0,n.yg)("h3",{id:"graphql-api"},"GraphQL API"),(0,n.yg)("p",null,"Assertions are fully accessible via DataHub's GraphQL API:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Query assertions and their run history"),(0,n.yg)("li",{parentName:"ul"},"Create and update native assertions"),(0,n.yg)("li",{parentName:"ul"},"Delete assertions"),(0,n.yg)("li",{parentName:"ul"},"Retrieve assertions for a specific dataset")),(0,n.yg)("p",null,"Key GraphQL types:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"Assertion"),": The main assertion entity"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"AssertionInfo"),": Assertion definition and type"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"AssertionRunEvent"),": Evaluation results"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"AssertionSource"),": Origin metadata")),(0,n.yg)("h3",{id:"integration-with-dbt"},"Integration with dbt"),(0,n.yg)("p",null,"DataHub's dbt integration automatically converts dbt tests into assertions:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Schema Tests"),": Mapped to field assertions (not_null, unique, accepted_values, relationships)"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Data Tests"),": Mapped to SQL assertions"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Test Metadata"),": Test severity, tags, and descriptions are preserved")),(0,n.yg)("h3",{id:"integration-with-great-expectations"},"Integration with Great Expectations"),(0,n.yg)("p",null,"The Great Expectations integration maps expectations to assertion types:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Column expectations \u2192 Field assertions"),(0,n.yg)("li",{parentName:"ul"},"Table expectations \u2192 Volume or schema assertions"),(0,n.yg)("li",{parentName:"ul"},"Custom expectations \u2192 Custom assertions")),(0,n.yg)("p",null,"Each expectation suite becomes a collection of assertions in DataHub."),(0,n.yg)("h3",{id:"integration-with-snowflake-data-quality"},"Integration with Snowflake Data Quality"),(0,n.yg)("p",null,"Snowflake DMF (Data Metric Functions) rules are ingested as assertions:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Row count rules \u2192 Volume assertions"),(0,n.yg)("li",{parentName:"ul"},"Uniqueness rules \u2192 Field metric assertions"),(0,n.yg)("li",{parentName:"ul"},"Freshness rules \u2192 Freshness assertions"),(0,n.yg)("li",{parentName:"ul"},"Custom metric rules \u2192 SQL assertions")),(0,n.yg)("h2",{id:"notable-exceptions"},"Notable Exceptions"),(0,n.yg)("h3",{id:"legacy-dataset-assertion-type"},"Legacy Dataset Assertion Type"),(0,n.yg)("p",null,"The ",(0,n.yg)("inlineCode",{parentName:"p"},"DATASET")," assertion type is a legacy format that predates the more specific field, volume, freshness, and schema assertion types. It uses ",(0,n.yg)("inlineCode",{parentName:"p"},"DatasetAssertionInfo")," with a generic structure. New integrations should use the more specific assertion types (FIELD, VOLUME, FRESHNESS, DATA_SCHEMA, SQL) as they provide better type safety and UI rendering."),(0,n.yg)("h3",{id:"assertion-results-vs-assertion-metrics"},"Assertion Results vs. Assertion Metrics"),(0,n.yg)("p",null,"While assertions track pass/fail status, DataHub also supports more detailed metrics through the ",(0,n.yg)("inlineCode",{parentName:"p"},"AssertionResult")," object:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"actualAggValue"),": The actual value observed (for numeric assertions)"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"externalUrl"),": Link to detailed results in the source system"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"nativeResults"),": Platform-specific result details")),(0,n.yg)("p",null,"This enables richer debugging and understanding of why assertions fail."),(0,n.yg)("h3",{id:"assertion-scheduling"},"Assertion Scheduling"),(0,n.yg)("p",null,"DataHub tracks when assertions run through ",(0,n.yg)("inlineCode",{parentName:"p"},"assertionRunEvent")," timeseries data, but does not directly schedule assertion evaluations. Scheduling is handled by:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Native Assertions"),": DataHub Cloud's built-in scheduler"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"External Assertions"),": The source platform's scheduler (dbt, Airflow, etc.)"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"On-Demand"),": Manual or API-triggered evaluations")),(0,n.yg)("p",null,"DataHub provides monitoring and alerting based on the assertion run events, regardless of the scheduling mechanism."),(0,n.yg)("h3",{id:"assertion-vs-test-results"},"Assertion vs. Test Results"),(0,n.yg)("p",null,"DataHub has two related concepts:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Assertions"),": First-class entities that define data quality rules"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Test Results"),": A simpler aspect that can be attached to datasets")),(0,n.yg)("p",null,"Test results are lightweight pass/fail indicators without the full expressiveness of assertions. Use assertions for production data quality monitoring and test results for simple ingestion-time validation."),(0,n.yg)("h2",{id:"technical-reference"},"Technical Reference"),(0,n.yg)("p",null,"For technical details about fields, searchability, and relationships, view the ",(0,n.yg)("strong",{parentName:"p"},"Columns")," tab in DataHub."))}y.isMDXComponent=!0}}]);